#!/usr/bin/env python3
"""
æµ‹è¯• KV cache SSD è¯»å†™åŠŸèƒ½ - ä½¿ç”¨ block ç´¢å¼•
éªŒè¯ push() å†™å…¥å’Œ _load_from_ssd() è¯»å–çš„ä¸€è‡´æ€§
"""

import torch
import numpy as np
import sys
import os

# æ·»åŠ  llama3 æ¨¡å—è·¯å¾„
sys.path.insert(0, os.path.dirname(__file__))

from llama3.SSDBacked import RawBlockKVBackend


def test_single_block_rw():
    """æµ‹è¯•å•ä¸ª block çš„è¯»å†™"""
    print("=" * 60)
    print("Test 1: Single Block Read/Write")
    print("=" * 60)

    # å‚æ•°è®¾ç½®
    ssd_device = "/dev/nvme0n1p4"
    n_layers = 2
    max_batch = 1
    heads = 8
    dim = 128
    n_blocks = 10

    # è®¡ç®— block å¤§å° (K + V)
    block_nbytes = (max_batch * heads * dim * 2) * 2  # fp16 = 2 bytes

    try:
        # åˆå§‹åŒ– SSD backend
        ssd = RawBlockKVBackend(
            dev_path=ssd_device,
            n_layers=n_layers,
            blk_bytes=block_nbytes,
            blk_per_layer=n_blocks,
            max_concurrent_io=4
        )
        print(f"âœ“ SSD backend initialized: {ssd_device}")
        print(f"  - Layers: {n_layers}")
        print(f"  - Blocks per layer: {n_blocks}")
        print(f"  - Block size: {block_nbytes} bytes ({block_nbytes / 1024:.2f} KB)")
        print(f"  - Aligned stride: {ssd.stride} bytes")

    except Exception as e:
        print(f"âœ— Failed to initialize SSD backend: {e}")
        return False

    # æµ‹è¯•æ•°æ®ç”Ÿæˆ
    layer = 0
    blk = 3

    # åˆ›å»ºæµ‹è¯•æ•°æ®ï¼šK å’Œ V
    k_test = torch.randn(max_batch, heads, dim, dtype=torch.float16)
    v_test = torch.randn(max_batch, heads, dim, dtype=torch.float16)

    # æ‰“åŒ…ä¸º KV (max_batch, heads, 2*dim)
    kv_pack = torch.cat([k_test, v_test], dim=-1)

    print(f"\nğŸ“ Writing test data to Layer {layer}, Block {blk}")
    print(f"  - K shape: {k_test.shape}")
    print(f"  - V shape: {v_test.shape}")
    print(f"  - KV pack shape: {kv_pack.shape}")
    print(f"  - Data size: {kv_pack.numel() * 2} bytes")

    # å†™å…¥ SSD
    try:
        ssd.write(layer, blk, kv_pack, sync=True)
        print("âœ“ Write completed (sync)")
    except Exception as e:
        print(f"âœ— Write failed: {e}")
        return False

    # ä» SSD è¯»å–
    print(f"\nğŸ“– Reading data from Layer {layer}, Block {blk}")
    kv_read_gpu = torch.empty_like(kv_pack, device='cuda:0')

    try:
        ssd.read(layer, blk, kv_read_gpu)
        torch.cuda.synchronize()
        print("âœ“ Read completed")
    except Exception as e:
        print(f"âœ— Read failed: {e}")
        return False

    # éªŒè¯æ•°æ®
    kv_read = kv_read_gpu.cpu()
    k_read, v_read = kv_read.split(dim, dim=-1)

    k_diff = (k_test - k_read).abs().max().item()
    v_diff = (v_test - v_read).abs().max().item()

    print(f"\nğŸ” Data verification:")
    print(f"  - K max diff: {k_diff}")
    print(f"  - V max diff: {v_diff}")

    if k_diff < 1e-5 and v_diff < 1e-5:
        print("âœ“ Data integrity verified!")
        return True
    else:
        print("âœ— Data mismatch detected!")
        return False


def test_batch_write_contiguous():
    """æµ‹è¯•è¿ç»­ blocks çš„æ‰¹é‡å†™å…¥"""
    print("\n" + "=" * 60)
    print("Test 2: Batch Write (Contiguous Blocks)")
    print("=" * 60)

    ssd_device = "/dev/nvme0n1p4"
    n_layers = 2
    max_batch = 1
    heads = 8
    dim = 128
    n_blocks = 20

    block_nbytes = (max_batch * heads * dim * 2) * 2

    try:
        ssd = RawBlockKVBackend(
            dev_path=ssd_device,
            n_layers=n_layers,
            blk_bytes=block_nbytes,
            blk_per_layer=n_blocks,
            max_concurrent_io=4
        )
        print(f"âœ“ SSD backend initialized")
    except Exception as e:
        print(f"âœ— Failed to initialize: {e}")
        return False

    # å‡†å¤‡è¿ç»­çš„ blocks: 5, 6, 7, 8
    layer = 1
    slots = [5, 6, 7, 8]
    tensors = []

    print(f"\nğŸ“ Preparing {len(slots)} contiguous blocks for Layer {layer}")
    print(f"  - Block indices: {slots}")

    for i, slot in enumerate(slots):
        k = torch.full((max_batch, heads, dim), fill_value=float(slot * 10 + i), dtype=torch.float16)
        v = torch.full((max_batch, heads, dim), fill_value=float(slot * 10 + i + 0.5), dtype=torch.float16)
        kv_pack = torch.cat([k, v], dim=-1)
        tensors.append(kv_pack)

    # æ‰¹é‡å†™å…¥
    try:
        ssd.write_batch(layer, slots, tensors, sync=True)
        print("âœ“ Batch write completed (contiguous optimization)")
    except Exception as e:
        print(f"âœ— Batch write failed: {e}")
        return False

    # é€ä¸ªè¯»å–éªŒè¯
    print(f"\nğŸ“– Reading and verifying each block...")
    all_ok = True

    for i, slot in enumerate(slots):
        kv_read_gpu = torch.empty(max_batch, heads, dim * 2, dtype=torch.float16, device='cuda:0')
        ssd.read(layer, slot, kv_read_gpu)
        torch.cuda.synchronize()

        kv_read = kv_read_gpu.cpu()
        k_read, v_read = kv_read.split(dim, dim=-1)

        expected_k = float(slot * 10 + i)
        expected_v = float(slot * 10 + i + 0.5)

        k_val = k_read[0, 0, 0].item()
        v_val = v_read[0, 0, 0].item()

        # Use relative tolerance for large values due to fp16 precision limits
        # fp16 has ~3 decimal digits of precision, so use 0.1% relative tolerance
        k_tol = max(0.01, abs(expected_k) * 0.001)
        v_tol = max(0.01, abs(expected_v) * 0.001)
        k_ok = abs(k_val - expected_k) < k_tol
        v_ok = abs(v_val - expected_v) < v_tol

        status = "âœ“" if (k_ok and v_ok) else "âœ—"
        print(f"  {status} Block {slot}: K={k_val:.1f} (expect {expected_k}), V={v_val:.1f} (expect {expected_v})")

        if not (k_ok and v_ok):
            all_ok = False

    if all_ok:
        print("âœ“ All blocks verified successfully!")
        return True
    else:
        print("âœ— Some blocks failed verification")
        return False


def test_batch_write_non_contiguous():
    """æµ‹è¯•éè¿ç»­ blocks çš„æ‰¹é‡å†™å…¥"""
    print("\n" + "=" * 60)
    print("Test 3: Batch Write (Non-Contiguous Blocks)")
    print("=" * 60)

    ssd_device = "/dev/nvme0n1p4"
    n_layers = 2
    max_batch = 1
    heads = 8
    dim = 128
    n_blocks = 20

    block_nbytes = (max_batch * heads * dim * 2) * 2

    try:
        ssd = RawBlockKVBackend(
            dev_path=ssd_device,
            n_layers=n_layers,
            blk_bytes=block_nbytes,
            blk_per_layer=n_blocks,
            max_concurrent_io=4
        )
        print(f"âœ“ SSD backend initialized")
    except Exception as e:
        print(f"âœ— Failed to initialize: {e}")
        return False

    # å‡†å¤‡éè¿ç»­çš„ blocks: 2, 5, 9, 15
    layer = 0
    slots = [2, 5, 9, 15]
    tensors = []

    print(f"\nğŸ“ Preparing {len(slots)} non-contiguous blocks for Layer {layer}")
    print(f"  - Block indices: {slots}")

    for i, slot in enumerate(slots):
        k = torch.full((max_batch, heads, dim), fill_value=float(slot * 100 + i), dtype=torch.float16)
        v = torch.full((max_batch, heads, dim), fill_value=float(slot * 100 + i + 0.5), dtype=torch.float16)
        kv_pack = torch.cat([k, v], dim=-1)
        tensors.append(kv_pack)

    # æ‰¹é‡å†™å…¥
    try:
        ssd.write_batch(layer, slots, tensors, sync=True)
        print("âœ“ Batch write completed (individual writes)")
    except Exception as e:
        print(f"âœ— Batch write failed: {e}")
        return False

    # é€ä¸ªè¯»å–éªŒè¯
    print(f"\nğŸ“– Reading and verifying each block...")
    all_ok = True

    for i, slot in enumerate(slots):
        kv_read_gpu = torch.empty(max_batch, heads, dim * 2, dtype=torch.float16, device='cuda:0')
        ssd.read(layer, slot, kv_read_gpu)
        torch.cuda.synchronize()

        kv_read = kv_read_gpu.cpu()
        k_read, v_read = kv_read.split(dim, dim=-1)

        expected_k = float(slot * 100 + i)
        expected_v = float(slot * 100 + i + 0.5)

        k_val = k_read[0, 0, 0].item()
        v_val = v_read[0, 0, 0].item()

        # Use relative tolerance for large values due to fp16 precision limits
        # fp16 has ~3 decimal digits of precision, so use 0.1% relative tolerance
        k_tol = max(0.01, abs(expected_k) * 0.001)
        v_tol = max(0.01, abs(expected_v) * 0.001)
        k_ok = abs(k_val - expected_k) < k_tol
        v_ok = abs(v_val - expected_v) < v_tol

        status = "âœ“" if (k_ok and v_ok) else "âœ—"
        print(f"  {status} Block {slot}: K={k_val:.1f} (expect {expected_k}), V={v_val:.1f} (expect {expected_v})")

        if not (k_ok and v_ok):
            all_ok = False

    if all_ok:
        print("âœ“ All blocks verified successfully!")
        return True
    else:
        print("âœ— Some blocks failed verification")
        return False


def main():
    print("KV Cache SSD Block Addressing Test Suite")
    print("=" * 60)
    print()

    # æ£€æŸ¥ CUDA å¯ç”¨æ€§
    if not torch.cuda.is_available():
        print("âœ— CUDA is not available. Cannot run tests.")
        return 1

    print(f"âœ“ CUDA is available: {torch.cuda.get_device_name(0)}")
    print()

    # è¿è¡Œæµ‹è¯•
    results = []

    # Test 1: å•ä¸ª block è¯»å†™
    try:
        results.append(("Single Block R/W", test_single_block_rw()))
    except Exception as e:
        print(f"\nâœ— Test 1 crashed: {e}")
        results.append(("Single Block R/W", False))

    # Test 2: è¿ç»­ blocks æ‰¹é‡å†™å…¥
    try:
        results.append(("Batch Contiguous", test_batch_write_contiguous()))
    except Exception as e:
        print(f"\nâœ— Test 2 crashed: {e}")
        results.append(("Batch Contiguous", False))

    # Test 3: éè¿ç»­ blocks æ‰¹é‡å†™å…¥
    try:
        results.append(("Batch Non-Contiguous", test_batch_write_non_contiguous()))
    except Exception as e:
        print(f"\nâœ— Test 3 crashed: {e}")
        results.append(("Batch Non-Contiguous", False))

    # æ€»ç»“
    print("\n" + "=" * 60)
    print("Test Summary")
    print("=" * 60)

    passed = 0
    for name, result in results:
        status = "âœ“ PASS" if result else "âœ— FAIL"
        print(f"{status}: {name}")
        if result:
            passed += 1

    print(f"\nTotal: {passed}/{len(results)} tests passed")

    return 0 if passed == len(results) else 1


if __name__ == "__main__":
    sys.exit(main())
