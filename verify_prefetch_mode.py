#!/usr/bin/env python3
"""
éªŒè¯ Weight Streaming å’Œ Prefetch æ¨¡å¼çš„è¯Šæ–­å·¥å…·
"""

import subprocess
import sys
import re
from typing import Dict, List, Tuple

def analyze_wsm_logs(stdout: str) -> Dict:
    """åˆ†æ WSM æ—¥å¿—è¾“å‡º"""
    
    # ç»Ÿè®¡ä¸åŒç±»å‹çš„æ“ä½œ
    prefetch_count = len(re.findall(r'\[WSM\] prefetch layer=\d+', stdout))
    evict_count = len(re.findall(r'\[WSM\]\s+evict layer=\d+', stdout))
    gpu_load_count = len(re.findall(r'\[WSM\] ->GPU layer=\d+', stdout))
    warmup_count = len(re.findall(r'\[WSM\] warmup prefetch:', stdout))
    
    # æå–å±‚æ“ä½œåºåˆ—
    layer_ops = []
    for match in re.finditer(r'\[WSM\] (prefetch|evict|->GPU) layer=(\d+)', stdout):
        op_type = match.group(1)
        layer_id = int(match.group(2))
        layer_ops.append((op_type, layer_id))
    
    # åˆ†æå†…å­˜ä½¿ç”¨
    memory_match = re.search(r'Peak GPU memory:\s+([0-9.]+)\s+([A-Z]+)', stdout)
    peak_memory = None
    if memory_match:
        value = float(memory_match.group(1))
        unit = memory_match.group(2)
        peak_memory = f"{value} {unit}"
    
    # åˆ†æä¼ è¾“ç»Ÿè®¡
    dram_gpu_ops = 0
    gpu_dram_ops = 0
    
    dram_gpu_match = re.search(r'DRAM â†’ GPU:\s+Operations: (\d+)', stdout)
    if dram_gpu_match:
        dram_gpu_ops = int(dram_gpu_match.group(1))
        
    gpu_dram_match = re.search(r'GPU â†’ DRAM:\s+Operations: (\d+)', stdout)
    if gpu_dram_match:
        gpu_dram_ops = int(gpu_dram_match.group(1))
    
    return {
        'prefetch_count': prefetch_count,
        'evict_count': evict_count,
        'gpu_load_count': gpu_load_count,
        'warmup_count': warmup_count,
        'layer_ops': layer_ops,
        'peak_memory': peak_memory,
        'dram_gpu_ops': dram_gpu_ops,
        'gpu_dram_ops': gpu_dram_ops,
        'total_transfer_ops': dram_gpu_ops + gpu_dram_ops
    }

def check_streaming_indicators(stdout: str) -> Dict[str, bool]:
    """æ£€æŸ¥æƒé‡æµå¼ä¼ è¾“çš„å„ç§æŒ‡æ ‡"""
    
    indicators = {}
    
    # 1. WSM å¯ç”¨æ£€æŸ¥
    indicators['wsm_enabled'] = 'Weight streaming enabled' in stdout
    
    # 2. æ£€æŸ¥æ˜¯å¦æœ‰å±‚æƒé‡åœ¨ CPUï¼ˆåº”è¯¥æœ‰ï¼‰
    indicators['layers_on_cpu'] = 'first block param device: cpu' in stdout
    
    # 3. æ£€æŸ¥æ˜¯å¦æœ‰ WSM æ“ä½œæ—¥å¿—
    indicators['wsm_operations'] = '[WSM]' in stdout
    
    # 4. æ£€æŸ¥æ˜¯å¦æœ‰è®¾å¤‡åŒæ­¥
    indicators['device_sync'] = 'Synchronizing layer norms to GPU' in stdout
    
    # 5. æ£€æŸ¥æ˜¯å¦æœ‰é¢„çƒ­
    indicators['warmup_prefetch'] = 'warmup prefetch:' in stdout
    
    # 6. æ£€æŸ¥é”™è¯¯
    indicators['no_device_errors'] = 'Expected all tensors to be on the same device' not in stdout
    indicators['no_method_errors'] = 'ensure_weights_cuda' not in stdout
    
    return indicators

def print_analysis_report(analysis: Dict, indicators: Dict[str, bool]):
    """æ‰“å°åˆ†ææŠ¥å‘Š"""
    
    print("ğŸ” Weight Streaming & Prefetch æ¨¡å¼éªŒè¯æŠ¥å‘Š")
    print("=" * 60)
    
    # 1. åŸºæœ¬æŒ‡æ ‡
    print("\nğŸ“Š WSM æ“ä½œç»Ÿè®¡:")
    print(f"   Prefetch æ“ä½œ: {analysis['prefetch_count']}")
    print(f"   Evict æ“ä½œ: {analysis['evict_count']}")  
    print(f"   GPU åŠ è½½æ“ä½œ: {analysis['gpu_load_count']}")
    print(f"   é¢„çƒ­æ“ä½œ: {analysis['warmup_count']}")
    
    # 2. ä¼ è¾“ç»Ÿè®¡
    print(f"\nğŸ’¾ å†…å­˜ä¼ è¾“ç»Ÿè®¡:")
    print(f"   DRAMâ†’GPU æ“ä½œ: {analysis['dram_gpu_ops']}")
    print(f"   GPUâ†’DRAM æ“ä½œ: {analysis['gpu_dram_ops']}")
    print(f"   æ€»ä¼ è¾“æ“ä½œ: {analysis['total_transfer_ops']}")
    
    # 3. å†…å­˜ä½¿ç”¨
    if analysis['peak_memory']:
        print(f"\nğŸ§  GPU å†…å­˜ä½¿ç”¨:")
        print(f"   å³°å€¼å†…å­˜: {analysis['peak_memory']}")
    
    # 4. æµå¼ä¼ è¾“æŒ‡æ ‡
    print(f"\nâœ… æµå¼ä¼ è¾“æŒ‡æ ‡æ£€æŸ¥:")
    for key, value in indicators.items():
        status = "âœ…" if value else "âŒ"
        key_desc = {
            'wsm_enabled': 'WSM å·²å¯ç”¨',
            'layers_on_cpu': 'å±‚æƒé‡ä¿æŒåœ¨ CPU',
            'wsm_operations': 'WSM æ“ä½œæ—¥å¿—å­˜åœ¨',
            'device_sync': 'è®¾å¤‡åŒæ­¥æ‰§è¡Œ',
            'warmup_prefetch': 'é¢„çƒ­é¢„å–æ‰§è¡Œ',
            'no_device_errors': 'æ— è®¾å¤‡ä¸åŒ¹é…é”™è¯¯',
            'no_method_errors': 'æ— æ–¹æ³•ç¼ºå¤±é”™è¯¯'
        }
        print(f"   {status} {key_desc.get(key, key)}: {value}")
    
    # 5. æ€»ç»“åˆ¤æ–­
    print(f"\nğŸ¯ **æœ€ç»ˆåˆ¤æ–­**:")
    
    is_prefetch_mode = (
        analysis['prefetch_count'] > 0 and 
        analysis['evict_count'] > 0 and
        analysis['total_transfer_ops'] > 50 and  # è¶³å¤Ÿå¤šçš„ä¼ è¾“æ“ä½œ
        indicators['wsm_enabled'] and
        indicators['layers_on_cpu']
    )
    
    if is_prefetch_mode:
        print("   âœ… **ç¡®è®¤ï¼šæ­£åœ¨ä½¿ç”¨ Prefetch é€å±‚åŠ è½½æ¨¡å¼**")
        print("   ğŸ“‹ è¯æ®:")
        print(f"      - WSM prefetch æ“ä½œ: {analysis['prefetch_count']} æ¬¡")
        print(f"      - WSM evict æ“ä½œ: {analysis['evict_count']} æ¬¡")
        print(f"      - å†…å­˜ä¼ è¾“æ“ä½œ: {analysis['total_transfer_ops']} æ¬¡")
        print("      - å±‚æƒé‡ä¿æŒåœ¨ CPUï¼ŒæŒ‰éœ€åŠ è½½åˆ° GPU")
    else:
        print("   âŒ **æœªä½¿ç”¨ Prefetch é€å±‚åŠ è½½æ¨¡å¼**")
        print("   å¯èƒ½åŸå› :")
        if analysis['prefetch_count'] == 0:
            print("      - æ²¡æœ‰æ£€æµ‹åˆ° prefetch æ“ä½œ")
        if analysis['total_transfer_ops'] < 50:
            print("      - å†…å­˜ä¼ è¾“æ“ä½œå¤ªå°‘ï¼Œå¯èƒ½æ˜¯å…¨é‡åŠ è½½")
        if not indicators['wsm_enabled']:
            print("      - WSM æœªå¯ç”¨")

def main():
    """ä¸»å‡½æ•°"""
    
    print("ğŸ§ª è¿è¡Œ Weight Streaming éªŒè¯æµ‹è¯•...")
    
    # è¿è¡Œæµ‹è¯•
    cmd = [
        'python3', '/home/roger/llama3_project/scripts/profile_pipeline.py',
        '--model-path', '/mnt/model/llama/checkpoints/Llama3.2-3B',
        '--prompt', 'Hello world test for WSM prefetch mode verification',
        '--max-gen-len', '5',  # çŸ­ä¸€ç‚¹ï¼Œå¿«é€Ÿæµ‹è¯•
        '--batch-size', '1',
        '--device', 'cuda',
        '--verbose'
    ]
    
    try:
        result = subprocess.run(cmd, capture_output=True, text=True, timeout=60)
        stdout = result.stdout
        stderr = result.stderr
        
        if result.returncode != 0:
            print(f"âŒ æµ‹è¯•å¤±è´¥ï¼Œè¿”å›ç : {result.returncode}")
            print(f"é”™è¯¯è¾“å‡º: {stderr}")
            return False
        
        # åˆ†æç»“æœ
        analysis = analyze_wsm_logs(stdout)
        indicators = check_streaming_indicators(stdout)
        
        # æ‰“å°æŠ¥å‘Š
        print_analysis_report(analysis, indicators)
        
        return True
        
    except subprocess.TimeoutExpired:
        print("âŒ æµ‹è¯•è¶…æ—¶")
        return False
    except Exception as e:
        print(f"âŒ æµ‹è¯•å‡ºé”™: {e}")
        return False

if __name__ == "__main__":
    success = main()
    sys.exit(0 if success else 1)