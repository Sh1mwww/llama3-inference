import math, os
from typing import Optional, List, Dict
import torch, torch.nn as nn, torch.nn.functional as F
import threading
import logging
from contextlib import contextmanager
import time
from torch.backends.cuda import sdp_kernel as sdpa_kernel
# é…ç½®æ—¥å¿—
logger = logging.getLogger(__name__)

# NVTX profiling support
try:
    import torch.cuda.nvtx as nvtx
    NVTX_AVAILABLE = True
except ImportError:
    NVTX_AVAILABLE = False
    # Fallback no-op functions
    class nvtx:
        @staticmethod
        def range_push(name): pass
        @staticmethod
        def range_pop(): pass

from .config import ModelArgs
from .kv_offload import KVOffloader, BLOCK
from .global_state_tracker import GlobalStateTracker, get_global_tracker, init_global_tracker

# ---------- Global Thread Pool for Async Forward ----------
from concurrent.futures import ThreadPoolExecutor

_EXECUTOR_SINGLETON = None
_EXECUTOR_LOCK = threading.Lock()

def _get_executor():
    """
    è·å–å…¨å±€çº¿ç¨‹æ± å•ä¾‹ï¼Œç”¨äº forward_async çš„å¼‚æ­¥æ”¶å°¾ã€‚
    æ¯ä¸ªè¿›ç¨‹å…±äº«ä¸€ä¸ªè½»é‡çº¿ç¨‹æ± ï¼ˆä¹Ÿå¯æ”¾åˆ° Transformer é‡Œå…¨å±€æŒæœ‰ï¼‰ã€‚
    å‰å‘åªæœ‰æå°‘çš„"æ”¶å°¾å›è°ƒ"ï¼Œ2~4 ä¸ªçº¿ç¨‹è¶³çŸ£ã€‚
    """
    global _EXECUTOR_SINGLETON
    if _EXECUTOR_SINGLETON is None:
        with _EXECUTOR_LOCK:
            if _EXECUTOR_SINGLETON is None:
                _EXECUTOR_SINGLETON = ThreadPoolExecutor(max_workers=4, thread_name_prefix="fwd_async")
    return _EXECUTOR_SINGLETON

# ---------- Stub Parameter Helper ----------
def make_stub_linear(in_features, out_features, bias=False, dtype=torch.bfloat16, device="cpu"):
    """åˆ›å»ºä¸€ä¸ªç©ºéª¨æ¶ nn.Linearï¼Œæƒé‡ä¸º 0-size stubï¼Œé¿å…å†…å­˜åˆ†é…"""
    # å…ˆç”¨ meta device åˆ›å»º Linearï¼ˆé¿å…åˆå§‹åŒ–ï¼‰
    with torch.device("meta"):
        linear = nn.Linear(in_features, out_features, bias=bias, dtype=dtype)

    # æ›¿æ¢æƒé‡ä¸º CPU ä¸Šçš„ 0-size stub
    stub_weight = torch.nn.Parameter(
        torch.empty(0, dtype=dtype, device=device),
        requires_grad=False
    )
    stub_weight._shape_hint = (out_features, in_features)  # ä¿ç•™å½¢çŠ¶ä¿¡æ¯
    linear.weight = stub_weight

    if bias:
        stub_bias = torch.nn.Parameter(
            torch.empty(0, dtype=dtype, device=device),
            requires_grad=False
        )
        stub_bias._shape_hint = (out_features,)
        linear.bias = stub_bias

    return linear
# ---------- Enhanced timing util ----------
class PerformanceTracker:
    def __init__(self):
        self.stats = {
            "weights_hbm_us": 0,
            "kv_fetch_us": 0, 
            "attn_us": 0,
            "ffn_us": 0,
            "total_forward_us": 0,
            "memory_alloc_us": 0,
        }
        self.layer_stats = {}  # per-layer statistics
        self.lock = threading.Lock()
    
    def reset(self):
        with self.lock:
            for key in self.stats:
                self.stats[key] = 0
            self.layer_stats.clear()
    
    def get_stats(self) -> Dict:
        with self.lock:
            return {
                "global": self.stats.copy(),
                "per_layer": self.layer_stats.copy()
            }
    
    def add_layer_stat(self, layer_id: int, stat_name: str, value: float):
        with self.lock:
            if layer_id not in self.layer_stats:
                self.layer_stats[layer_id] = {}
            if stat_name not in self.layer_stats[layer_id]:
                self.layer_stats[layer_id][stat_name] = 0
            self.layer_stats[layer_id][stat_name] += value

PERF_TRACKER = PerformanceTracker()

# Profiling control via environment variable
PROFILE = os.getenv("LLM_PROFILE", "0") == "1"

@contextmanager
def cuda_timer(key: str, layer_id: Optional[int] = None):
    # No-op when profiling is disabled (é¿å…ä»»ä½•åŒæ­¥å¼€é”€)
    if not PROFILE:
        yield
        return

    if not torch.cuda.is_available():
        yield
        return

    start_event = None
    end_event = None
    cuda_error_occurred = False

    try:
        # Check CUDA context health before creating events
        try:
            torch.cuda.current_device()
        except RuntimeError:
            logger.warning(f"CUDA context unhealthy for {key}, skipping timing")
            yield
            return

        start_event = torch.cuda.Event(enable_timing=True)
        end_event = torch.cuda.Event(enable_timing=True)

        start_event.record()
        yield
        
    except torch.cuda.OutOfMemoryError as e:
        logger.error(f"CUDA OOM in timer for {key}: {e}")
        cuda_error_occurred = True
        torch.cuda.empty_cache()
        raise
    except RuntimeError as e:
        if "CUDA" in str(e):
            logger.error(f"CUDA error in timer for {key}: {e}")
            cuda_error_occurred = True
            raise
        else:
            logger.error(f"Runtime error in timer for {key}: {e}")
            raise
    finally:
        # Only attempt cleanup if no CUDA error occurred and events were created
        if not cuda_error_occurred and start_event is not None and end_event is not None:
            try:
                # Check if CUDA context is still valid
                torch.cuda.current_device()
                
                end_event.record()
                # åªåŒæ­¥å½“å‰æµçš„äº‹ä»¶ï¼Œé¿å…å…¨å±€é˜»å¡å…¶å®ƒæµï¼ˆå°¤å…¶æ˜¯H2Dï¼‰
                end_event.synchronize()

                elapsed_us = int(start_event.elapsed_time(end_event) * 1000)

                with PERF_TRACKER.lock:
                    PERF_TRACKER.stats[key] += elapsed_us
                    if layer_id is not None:
                        # ç›´æ¥æ›´æ–°ï¼Œé¿å…åµŒå¥—é”
                        if layer_id not in PERF_TRACKER.layer_stats:
                            PERF_TRACKER.layer_stats[layer_id] = {}
                        if key not in PERF_TRACKER.layer_stats[layer_id]:
                            PERF_TRACKER.layer_stats[layer_id][key] = 0
                        PERF_TRACKER.layer_stats[layer_id][key] += elapsed_us
            except Exception as e:
                logger.warning(f"Error in cuda_timer cleanup for {key}: {e}")
                # Don't re-raise exceptions in cleanup

def set_weight_manager(manager):
    global WEIGHT_MANAGER
    WEIGHT_MANAGER = manager

def get_weight_manager(device: str):
    global WEIGHT_MANAGER
    return WEIGHT_MANAGER

# class RMSNorm(nn.Module):
#     def __init__(self, dim: int, eps: float = 1e-6):
#         super().__init__()
#         self.weight = nn.Parameter(torch.ones(dim))
#         self.eps = eps
    
#     def forward(self, x: torch.Tensor):
#         with cuda_timer("memory_alloc_us"):
#             norm = x.pow(2).mean(-1, keepdim=True).add(self.eps).rsqrt()
#         # é˜²å‘†ï¼šæŠŠæ¬Šé‡çš„ device / dtype å°é½Šè¼¸å…¥
#         w = self.weight
#         if(w.device != x.device):
#             w = w.to(device=x.device, dtype=x.dtype)
#         return w * (x * norm)
class RMSNorm(nn.Module):
    def __init__(self, dim: int, eps: float = 1e-6, *, dtype=torch.bfloat16, device=None, requires_grad=False):
        super().__init__()
        self.eps = float(eps)
        # æƒé‡ç›´æ¥ç”¨ç›®æ ‡ dtype/device åˆ›å»ºï¼Œæ¨ç†é»˜è®¤ä¸éœ€è¦æ¢¯åº¦
        self.weight = nn.Parameter(torch.ones(dim, dtype=dtype, device=device), requires_grad=requires_grad)

    def forward(self, x: torch.Tensor) -> torch.Tensor:
        # 1) è®¡ç®—ç”¨ fp32 æ›´ç¨³å®š
        y = x.to(torch.float32)
        # ç”¨ä¹˜æ³•ä»£æ›¿ powï¼Œå°‘ä¸€æ¬¡ kernel
        inv_rms = torch.rsqrt(y.mul(y).mean(dim=-1, keepdim=True).add_(self.eps))
        y = y.mul(inv_rms)                 # fp32

        # 2) è¾“å‡ºä¸¥æ ¼å›åˆ°è¾“å…¥ dtypeï¼ˆä¾‹å¦‚ bfloat16ï¼‰
        out = y.to(dtype=x.dtype)          # ä¸ä¸‹æ¸¸ Linear.weight çš„ dtype ä¸€è‡´

        # 3) ä»…åœ¨å¿…è¦æ—¶æŠŠæƒé‡å¯¹é½åˆ°è¾“å…¥çš„ device/dtypeï¼ˆå°½é‡é¿å…æ¯æ­¥ .toï¼‰
        w = self.weight
        if w.device != x.device:
            w = w.to(device=x.device, non_blocking=True)
        if w.dtype != x.dtype:
            w = w.to(dtype=x.dtype)

        return out * w


def precompute_theta_pos_frequencies(head_dim: int, seq_len: int, device: str, theta: float = 10000.0):
    assert head_dim % 2 == 0
    theta_i = 1.0 / (theta ** (torch.arange(0, head_dim, 2).float() / head_dim)).to(device)
    m = torch.arange(seq_len, device=device)
    freqs = torch.outer(m, theta_i)
    return torch.polar(torch.ones_like(freqs), freqs)

# def apply_rotary_embeddings(x: torch.Tensor, freqs_complex: torch.Tensor) -> torch.Tensor:
#     b, l, h, d = x.shape
#     x_ = x.float().reshape(b, l, h, d // 2, 2)
#     x_complex = torch.view_as_complex(x_)
#     freqs_complex = freqs_complex.unsqueeze(0).unsqueeze(2)
#     out = torch.view_as_real(x_complex * freqs_complex)
#     return out.reshape(b, l, h, d).type_as(x)
def apply_rotary_embeddings(x: torch.Tensor,
                            freqs_complex: torch.Tensor,
                            start_pos: int = 0) -> torch.Tensor:
    """
    x: (B, L, H, D)
    freqs_complex: æ”¯æŒä»¥ä¸‹ä»»ä¸€å½¢çŠ¶ï¼š
        - (L, D/2)                           # æœ€å¸¸è§
        - (1, L, 1, D/2)                     # å·²ç»è¢«æ‰©æˆ4D
        - (L, 1, D/2) / (1, L, D/2) / (L, D/2, 1)   # å…¶ä»–å¸¦1ç»´çš„å˜ä½“
    è¡Œä¸ºï¼š
        1) å…ˆæŠŠ freqs è§„èŒƒæˆ (L, D/2)
        2) åˆ‡ç‰‡åˆ° [start_pos : start_pos+Lx] å…¶ä¸­ Lx = x.shape[1]
        3) å¹¿æ’­ä¹˜åˆ° x çš„å‰ä¸€åŠç»´åº¦ï¼ˆè§†ä½œå¤æ•°ï¼‰
    """
    import torch
    B, Lx, H, D = x.shape
    if D % 2 != 0:
        raise RuntimeError(f"apply_rotary_embeddings: head_dim {D} must be even")

    # ---- è§„èŒƒ freqs åˆ° (L, D/2) ----
    fc = freqs_complex
    # å¸¸è§è¾“å…¥ï¼š(1, L, 1, D/2)
    if fc.dim() == 4 and fc.size(0) == 1 and fc.size(2) == 1:
        fc = fc.squeeze(0).squeeze(1) if fc.size(1) == 1 else fc.squeeze(0).squeeze(2)  # -> (L, D/2)
    # å…¶ä»–å¸¦ 1 çš„ä¸‰ç»´
    if fc.dim() == 3:
        # å°è¯•å»æ‰å•ä¾‹ç»´ï¼Œä¼˜å…ˆå»æ‰ä¸­é—´çš„ 1 ç»´
        if fc.size(1) == 1:
            fc = fc.squeeze(1)  # -> (L, D/2)
        elif fc.size(0) == 1:
            fc = fc.squeeze(0)  # -> (L, D/2)
        elif fc.size(2) == 1:
            fc = fc.squeeze(2)  # -> (L, D/2)
    # ä¸¤ç»´å°±ä¸ç”¨åŠ¨
    if fc.dim() != 2:
        # æœ€åå…œåº•ï¼šå¦‚æœç¬¬0ç»´æ­£å¥½ç­‰äº L æˆ– Lxï¼Œå°± reshape æˆ (L, D/2)
        if fc.size(0) in (Lx, fc.size(0)) and fc.numel() % fc.size(0) == 0:
            fc = fc.reshape(fc.size(0), -1)
        else:
            raise RuntimeError(f"apply_rotary_embeddings: unexpected freqs_complex shape {freqs_complex.shape}, "
                               f"cannot normalize to (L, D/2)")

    # ---- åˆ‡ç‰‡åˆ°å½“å‰çª—å£ [start_pos : start_pos+Lx] ----
    if fc.size(0) < start_pos + Lx:
        raise RuntimeError(f"apply_rotary_embeddings: freqs length {fc.size(0)} < needed {start_pos+Lx}")
    fc = fc[start_pos: start_pos + Lx, :]   # (Lx, D/2)

    # ---- è®¾å¤‡ä¸ dtype å¯¹é½ ----
    # x_è¢«è½¬ä¸º float åšå¤æ•°è§†å›¾ï¼Œæœ€ç»ˆå†è½¬æ¢å› x.dtype
    x_ = x.to(torch.float32).reshape(B, Lx, H, D // 2, 2)       # (B,L,H,D/2,2)
    x_complex = torch.view_as_complex(x_)                       # (B,L,H,D/2)
    fc = fc.to(dtype=x_complex.dtype, device=x.device)          # (Lx,D/2)

    # ---- å¹¿æ’­åˆ° (1,Lx,1,D/2) ä¸ x_complex ç›¸ä¹˜ ----
    fc = fc.unsqueeze(0).unsqueeze(2)                           # (1,Lx,1,D/2)
    out = torch.view_as_real(x_complex * fc)                    # (B,L,H,D/2,2)
    out = out.reshape(B, Lx, H, D).to(dtype=x.dtype)
    return out


# def repeat_kv(x: torch.Tensor, n_rep: int) -> torch.Tensor:
#     if n_rep == 1: 
#         return x
#     b, t, h, d = x.shape
#     return x[:, :, :, None, :].expand(b, t, h, n_rep, d).contiguous().view(b, t, h * n_rep, d)

class SelfAttention(nn.Module):
    def __init__(self, args: ModelArgs):
        super().__init__()
        self.n_kv_heads = args.n_heads if args.n_kv_heads is None else args.n_kv_heads
        self.n_heads_q = args.n_heads
        self.n_rep = self.n_heads_q // self.n_kv_heads
        self.head_dim = args.dim // args.n_heads
        self.kv_elapsed_time = 0.0
        self.attn_time = 0.0

        self.topk_blk = args.topk_blk
        self.device = args.device
        self.is_cuda = str(self.device).startswith("cuda") and torch.cuda.is_available()

        # Linearæƒé‡åˆå§‹åŒ– - ä½¿ç”¨ stub é¿å…å¤§å†…å­˜åˆ†é…
        use_stub = getattr(args, "use_stub_params", False)
        if use_stub:
            # SSD streaming æ¨¡å¼ï¼šä½¿ç”¨ 0-size stub
            self.wq = make_stub_linear(args.dim, self.n_heads_q * self.head_dim, bias=False)
            self.wk = make_stub_linear(args.dim, self.n_kv_heads * self.head_dim, bias=False)
            self.wv = make_stub_linear(args.dim, self.n_kv_heads * self.head_dim, bias=False)
            self.wo = make_stub_linear(args.n_heads * self.head_dim, args.dim, bias=False)
        else:
            # ä¼ ç»Ÿæ¨¡å¼ï¼šæ­£å¸¸åˆå§‹åŒ–
            _dev = getattr(args, "param_init_device", None)
            kw = ({"device": _dev} if _dev is not None else {})
            self.wq = nn.Linear(args.dim, self.n_heads_q * self.head_dim, bias=False, **kw)
            self.wk = nn.Linear(args.dim, self.n_kv_heads * self.head_dim, bias=False, **kw)
            self.wv = nn.Linear(args.dim, self.n_kv_heads * self.head_dim, bias=False, **kw)
            self.wo = nn.Linear(args.n_heads * self.head_dim, args.dim, bias=False, **kw)
        self.block_sz = BLOCK

        self.apply_causal_mask = True

        streams = None
        try:
            import llama3.stream_mnt as stream_mnt
            streams = stream_mnt.get_streams(args.device)
        except Exception:
            pass  # å›é€€åˆ°å†…éƒ¨æµåˆ›å»º

        self.streams = streams
        self.compute_stream = getattr(streams, "compute_mha", None) 
        self.weight_h2d_stream = getattr(streams, "weight_h2d_mha", None) 
        self.weight_manager = None

        # ç»„çº§é¢„å–æ”¯æŒæ ‡è®°
        self.supports_group_prefetch = False
        
        self.offloader = None   
        self.enable_profiling = False
        
        self.offloader = KVOffloader(
            layers=args.n_layers,
            heads=self.n_kv_heads,
            dim=self.head_dim,
            max_seq=args.max_seq_len,
            max_batch=args.max_batch_size,
            device=args.device,
            dtype_bytes=2,  # float16
            streams=streams
        )
        
        self.layer_id = -1
        self.attention_history = []  # ç”¨äºåˆ†ææ³¨æ„åŠ›æ¨¡å¼
        self.qkv_buffer = None
        # scores_buffer å·²ç§»é™¤ - Flash Attention ä¸éœ€è¦é¢„åˆ†é… [B,H,T,T] çŸ©é˜µ
        # self.streams = streams  # ä¿å­˜streamså¼•ç”¨ç”¨äºcompute
        
    def _get_causal_mask(self, t: int, device):
        # è‹¥ç¼“å­˜ä¸å­˜åœ¨ / å¤ªå° / è®¾å¤‡ä¸ä¸€è‡´ï¼Œå°±é‡å»º
        cm = getattr(self, "_causal_mask", None)
        if (cm is None) or (cm.device != device) or (cm.size(-1) < t):
            cm = torch.ones((1, 1, t, t), dtype=torch.bool, device=device).triu(1)
            try:
                self.register_buffer("_causal_mask", cm, persistent=False)
            except Exception:
                self._causal_mask = cm
        return cm[..., :t, :t]    
    
    @staticmethod
    def _safe_item_sum_1d(t: torch.Tensor, s: int, e: int) -> float:
        # t å¯èƒ½æ˜¯ metaï¼›ä¹Ÿå¯èƒ½ä¸ºç©º/Noneï¼›éƒ½ç»™å‡º 0.0
        if t is None:
            return 0.0
        if getattr(t, "is_meta", False) or (hasattr(t, "device") and t.device.type == "meta"):
            return 0.0
        if s >= t.size(0):
            return 0.0
        # ç”¨ detach().cpu().item() ä¿è¯ä¸æ˜¯ CUDA/Event ç­‰ç‰¹æ®Šå¼ é‡
        return float(t[s:e].sum().detach().cpu().item())
        
    
    def _get_modules_dict(self):
        return {
            "wq": self.wq,
            "wk": self.wk, 
            "wv": self.wv,
            "wo": self.wo
        }
    
    def _sync_event_safely(self, evt: torch.cuda.Event, timeout_ms: int = 5000):
        if not getattr(self, 'enable_profiling', False):
            return
        # è¼•é‡è¼ªè©¢ + timeoutï¼šé¿å…æŸäº›ç’°å¢ƒä¸‹äº‹ä»¶æ²’æœ‰è¢«æ­£ç¢ºè¨˜éŒ„å°è‡´æ°¸ä¹…ç­‰å¾…
        import time
        start = time.time()
        while not evt.query():
            if (time.time() - start) * 1000.0 > timeout_ms:
                # ä¸ä¸Ÿæ“²ç•°å¸¸ï¼Œæ‰“å°è­¦å‘Šä¸¦é€€å‡ºç­‰å¾…ï¼›é¿å…æ¸¬è©¦è¢«å¡æ­»
                print(f"[WARN][L{self.layer_id}] event sync timeout after {timeout_ms} ms")
                return
            time.sleep(0.001)
        # äº‹ä»¶å·²å®Œæˆï¼Œç„¡éœ€å†åŒæ­¥
        return
    
    def _ensure_weights_cuda(self):
        wm = getattr(self, "weight_manager", None)
        if wm is None:
            return
        if hasattr(wm, "wait_group_ready"):
            compute_stream = getattr(self.streams, "compute_attn", None)
            wm.wait_group_ready(self.layer_id, "attn", compute_stream=compute_stream)

    def _allocate_buffers(self, batch_size: int, seq_len: int, max_kv_len: int):
        """
        âš ï¸ æ­¤æ–¹æ³•ç›®å‰æœªè¢«ä½¿ç”¨ï¼ˆå·²æ”¹ç”¨ Flash Attentionï¼‰
        ä½¿ç”¨ scaled_dot_product_attention åï¼Œä¸å†éœ€è¦é¢„åˆ†é… attention scores buffer
        Flash Attention å†…éƒ¨ä½¿ç”¨ kernel fusionï¼Œé¿å…ç‰©åŒ– [B,H,T,T] çŸ©é˜µ

        ä¿ç•™æ­¤æ–¹æ³•ä»…ç”¨äºå‘åå…¼å®¹ï¼Œå¦‚æœéœ€è¦å›é€€åˆ°æ‰‹å†™ attention å¯ä»¥å‚è€ƒ
        """
        if (self.qkv_buffer is None or
            self.qkv_buffer[0].size(0) < batch_size or
            self.qkv_buffer[0].size(1) < seq_len):

            with cuda_timer("memory_alloc_us", self.layer_id):
                # æ³¨æ„ï¼šä½¿ç”¨ Flash Attention åï¼Œä¸å†éœ€è¦ scores_buffer
                # ä»¥ä¸‹ä»£ç ä»…åˆ†é… QKV buffersï¼ˆå¦‚æœéœ€è¦ï¼‰
                q_elements = batch_size * seq_len * self.n_heads_q * self.head_dim
                kv_elements = batch_size * seq_len * self.n_kv_heads * self.head_dim

                try:
                    from .memory_manager import GlobalMemoryManager
                    memory_manager = GlobalMemoryManager.get_instance()
                    if memory_manager:
                        # åªè®¡ç®— QKV çš„å†…å­˜éœ€æ±‚ï¼ˆä¸åŒ…æ‹¬ scoresï¼‰
                        total_bytes = (q_elements + 2 * kv_elements) * 2  # float16
                        if not memory_manager.can_allocate(total_bytes):
                            # å°è¯•æ¸…ç†å†…å­˜
                            if hasattr(self, 'qkv_buffer') and self.qkv_buffer:
                                del self.qkv_buffer
                            torch.cuda.empty_cache()

                            if not memory_manager.can_allocate(total_bytes):
                                raise RuntimeError(f"Insufficient GPU memory: need {total_bytes/(1024**3):.2f}GB")
                except ImportError:
                    pass  # memory_manager not available

                try:
                    # QKV buffer (å¦‚æœéœ€è¦)
                    q_shape = (batch_size, seq_len, self.n_heads_q, self.head_dim)
                    kv_shape = (batch_size, seq_len, self.n_kv_heads, self.head_dim)

                    self.qkv_buffer = (
                        torch.empty(q_shape, dtype=torch.float16, device=self.device),
                        torch.empty(kv_shape, dtype=torch.float16, device=self.device),
                        torch.empty(kv_shape, dtype=torch.float16, device=self.device)
                    )
                    # âœ… scores_buffer å·²ç§»é™¤ - Flash Attention ä¸éœ€è¦æ˜¾å¼åˆ†é…

                except torch.cuda.OutOfMemoryError as e:
                    logger.error(f"GPU OOM during buffer allocation: batch={batch_size}, seq={seq_len}")
                    torch.cuda.empty_cache()
                    raise RuntimeError(f"GPU OOM: Cannot allocate attention buffers. Try reducing batch_size (current: {batch_size}) or max sequence length.") from e
    
    def forward(self, x: torch.Tensor, start_pos: int, freqs_complex: torch.Tensor) -> torch.Tensor:
        # ============================================================
        # â­ å›ç»•é€šçŸ¥ + äº‹ä»¶ç­‰å¾…ï¼ˆå½»åº•ä¸å…œåº•ï¼‰
        # ============================================================
        wm = getattr(self, "weight_manager", None)
 
        # è¿™ä¸ä¼šæ”¹å˜ WSM çš„æƒé‡æµå¼è¡Œä¸ºï¼Œåªæ˜¯é˜²æ­¢æ¿€æ´»å›åˆ° CPU
        if x.device.type != "cuda":
            target_device = getattr(self, "device", "cuda:0")
            logger.warning(
                f"[SelfAttention L{self.layer_id}] Input x on {x.device}, moving to {target_device}. "
                f"This should not happen in normal flow - investigate upstream."
            )
            x = x.to(target_device, non_blocking=True)

        # â­â­â­ é˜²å¾¡å¼æ£€æŸ¥ï¼šæ¿€æ´»å¿…é¡»åœ¨ CUDA ä¸Šï¼ˆæ—©å¤±è´¥ï¼Œé¿å…åç»­éšå¼åŒæ­¥ï¼‰
        if not x.is_cuda:
            raise RuntimeError(
                f"[SelfAttention L{self.layer_id}] Input activation is on {x.device}, expected CUDA. "
                f"This indicates activation was incorrectly moved to CPU. Shape: {x.shape}, dtype: {x.dtype}"
            )

        # Check CUDA context health
        if x.is_cuda:
            try:
                torch.cuda.current_device()
            except RuntimeError as e:
                logger.error(f"CUDA context error in attention forward: {e}")
                raise RuntimeError("CUDA context is corrupted") from e

        start_time = time.time()
        assert x.dim()==3, f"x dim={x.dim()}, shape={x.shape}"
        bsz, seqlen, _ = x.shape


        def _ensure_cpu_scalar_attr(mod, name: str):
            if hasattr(mod, name):
                t = getattr(mod, name)
                if isinstance(t, torch.Tensor) and (getattr(t, "is_meta", False)
                                                    or (hasattr(t, "device") and t.device.type == "meta")):
                    setattr(mod, name, torch.zeros((), dtype=torch.int64, device="cpu"))
            else:
                # é¦–æ¬¡å»ºç«‹
                setattr(mod, name, torch.zeros((), dtype=torch.int64, device="cpu"))

        _ensure_cpu_scalar_attr(self, "attn_us")
        _ensure_cpu_scalar_attr(self, "total_forward_us")

        # â­ è°ƒè¯•æ—¥å¿—ï¼šä»…å½“ç¯å¢ƒå˜é‡å¯ç”¨æ—¶è¾“å‡ºï¼ˆé¿å… prefill é˜¶æ®µ CPU ç“¶é¢ˆï¼‰
        _verbose = os.getenv("ATTN_VERBOSE_LOG", "0") == "1"
        if _verbose:
            print(f"[ATTN] Layer {self.layer_id} forward starting...")

        # ============================================================
        # 1) åªç”¨äº‹ä»¶ã€ä¸é˜»å¡ï¼šæ ‡è®°ç»„ä½¿ç”¨ + ç­‰å¾…ç»„ ready äº‹ä»¶
        # ============================================================
        wm = getattr(self, "weight_manager", None)
        in_use = False
        try:
            if wm and hasattr(wm, "_mark_group_in_use"):
                wm._mark_group_in_use(self.layer_id, "attn")
                in_use = True

            # â­ åªç”¨äº‹ä»¶ç­‰å¾…ï¼Œä¸åšåŒæ­¥é˜»å¡
            # åœ¨ compute_mha æµä¸Šç­‰å¾… attn ç»„çš„ ready äº‹ä»¶ï¼ˆéé˜»å¡å¼ï¼Œåªè®©æµä¾èµ–äº‹ä»¶ï¼‰
            if wm is not None and hasattr(wm, "wait_group_ready"):
                #  é¢å¤–ä¿æŠ¤ï¼šåœ¨ ATTN å¼€å§‹æ—¶é¢„ pin åŒå±‚ FFNï¼Œé¿å…ç¼éš™è¢«é€å‡º
                if hasattr(wm, "pin_group"):
                    try: wm.pin_group(self.layer_id, "ffn", reason="pair")
                    except Exception: pass
                wm.wait_group_ready(self.layer_id, "attn", compute_stream=self.compute_stream)

                # âœ¨ Stub å…œåº•æ£€æŸ¥ï¼šç¡®ä¿æƒé‡å·²çœŸæ­£åŠ è½½ï¼ˆéç©º stubï¼‰
                if self.wq.weight.numel() == 0:
                    # WSM æ‰¿è¯ºçš„æƒé‡æœªåˆ°ä½ï¼Œå¼ºåˆ¶åŒæ­¥å›é€€ä¸€æ¬¡
                    print(f"[ATTN][L{self.layer_id}][ERROR] wq.weight is still stub after wait_group_ready!")
                    # å°è¯•å¼ºåˆ¶åŒæ­¥åŠ è½½ï¼ˆé˜»å¡ï¼‰
                    if hasattr(wm, "_group_is_resident"):
                        if not wm._group_is_resident(self.layer_id, "attn", wait_for_event=True):
                            raise RuntimeError(f"[ATTN][L{self.layer_id}] Cannot load weights: still stub after sync wait")
                    else:
                        raise RuntimeError(f"[ATTN][L{self.layer_id}] Cannot load weights: stub detected (no resident check)")

            # â­ å¯é€‰ï¼šç­‰å¾… KV å— ready äº‹ä»¶ï¼ˆå¦‚æœæœ‰é¢„å–ï¼‰
            # åœ¨ decode é˜¶æ®µï¼ˆstart_pos > 0ï¼‰ï¼Œç­‰å¾…æœ¬å±‚æ‰€éœ€çš„ KV å— H2D å®Œæˆ
            if start_pos > 0 and self.offloader is not None and hasattr(self.offloader, "wait_blocks_ready"):
                # è®¡ç®—æœ¬å±‚éœ€è¦çš„å—ï¼šæœ€è¿‘çª—å£ tokens
                blocks = self.offloader.plan_tail_window_blocks(start_pos, seqlen, window_tokens=BLOCK)
                if blocks:
                    self.offloader.wait_blocks_ready(self.layer_id, blocks, stream=self.compute_stream)

            if _verbose:
                print(f"[ATTN] Layer {self.layer_id} weights event wait done (non-blocking)")

            # æ›´æ–°å…¨å±€çŠ¶æ€è·Ÿè¸ªå™¨
            tracker = get_global_tracker()
            if tracker:
                batch_idx = tracker.current_batch
            else:
                batch_idx = 0

            if _verbose:
                print(f"[ATTN] Layer {self.layer_id} starting computation...")
            
            # â­â­â­ Background prefetch (compute-overlapped)
            try:
                wm = getattr(self, "weight_manager", None)

                # --- ç»„çº§æƒé‡é¢„å–ï¼šæœ¬å±‚ FFN + åç»­ D å±‚ ATTn ---
                # è¯´æ˜ï¼šprefetch_group_async å¹‚ç­‰ï¼›è‹¥è¯¥ç»„å·²åœ¨ GPU æˆ–æ­£åœ¨ H2Dï¼Œä¼šè¢« WSM è·³è¿‡
                if wm is not None and hasattr(wm, "prefetch_group_async"):
                    # 1) â­ å…ˆæŠŠ"æœ¬å±‚ FFN"æŒ‚èµ·å¹¶ PINï¼ˆé˜²æ­¢åœ¨ MHAâ†’FFN ç¼éš™ä¸­è¢«æ·˜æ±°ï¼‰
                    wm.prefetch_group_async(self.layer_id, "ffn", pin=True, reason="pair")
                    # 2) é¡¶è¡¥å»¶åï¼šç”± compute-done å›è°ƒè§¦å‘ï¼ˆé¿å…å‰å‘è·¯å¾„åŒæ­¥æ”¶ç¼©/è¡¥é½ï¼‰
                    #    è§ï¼šwm.notify_group_compute_done() çš„åå°çº¿ç¨‹

                # --- KVï¼šä¸ºâ€œä¸‹ä¸€å±‚æ³¨æ„åŠ›â€é¢„æ‹‰æœ€è¿‘çª—å£çš„å†å² KV åˆ° HBMï¼ˆä»… decode é˜¶æ®µï¼‰ ---
                # æ³¨æ„ï¼šstart_pos==0 ä¸º prefillï¼Œæ­¤æ—¶ä¸‹ä¸€å±‚å½“å‰å—å¯èƒ½å°šä¸å­˜åœ¨ï¼Œæ•…è·³è¿‡
                if (start_pos > 0) and getattr(self, "offloader", None) is not None:
                    # è¯¥æ–¹æ³•ä¼šï¼šå¿…è¦æ—¶å…ˆ SSD->DRAMï¼Œå†åœ¨ kv_h2d æµå‘èµ· DRAM->HBMï¼›å¹¶è®°å½•äº‹ä»¶ï¼Œfetch() å°†å‘½ä¸­
                    self.offloader.prefetch_for_next_layer(
                        current_layer=self.layer_id,
                        start_pos=int(start_pos),
                        seqlen=int(seqlen),
                        bsz=int(bsz),
                        window_tokens=BLOCK,
                    )
            except Exception as e:
                # éè‡´å‘½ï¼šä»»ä½•é¢„å–å¼‚å¸¸éƒ½ä¸å½±å“ä¸»è®¡ç®—è·¯å¾„
                if getattr(wm, "verbose", False):
                    print(f"[ATTN][L{self.layer_id}] background prefetch skipped: {e}")

            # é¢„æœŸå½¢çŠ¶
            exp_q = (self.n_heads_q * self.head_dim, x.size(-1))
            exp_kv = (self.n_kv_heads * self.head_dim, x.size(-1))

            def _shape(p: torch.nn.Parameter):
                # çœŸå®å½¢çŠ¶ä¼˜å…ˆï¼›stub æˆ– meta æ—¶è¯» _shape_hint
                if getattr(p, "is_meta", False) or (hasattr(p, "device") and p.device.type == "meta"):
                    return getattr(p, "_shape_hint", tuple(p.shape))
                if p.numel() == 0 and hasattr(p, "_shape_hint"):
                    return getattr(p, "_shape_hint")
                return tuple(p.shape)
            
            def _check_or_defer(p: torch.nn.Parameter, exp, name: str):
                shp = _shape(p)
                if shp != exp:
                    # å…è®¸åœ¨ WSM ç®¡ç†ä¸‹çš„ stub å…ˆâ€œé€šè¿‡â€ï¼ŒçœŸæ­£çš„ weight ä¼šç”± WSM åœ¨ H2D å®Œæˆåå®‰è£…
                    if p.numel() == 0 and getattr(self, "weight_manager", None) is not None:
                        if os.getenv("WSM_VERBOSE_MISMATCH", "0") == "1":
                            print(f"[ATTN][L{self.layer_id}] defer {name} shape check: stub {shp} -> expect {exp}")
                        return
                    raise RuntimeError(f"[{name} shape] {shp} != {exp} (dim/head config mismatch?)")

            # if _shape(self.wq.weight) != exp_q:
            #     raise RuntimeError(f"[Q shape] { _shape(self.wq.weight) } != {exp_q} "
            #                     f"(likely manifest q/k/v mapping issue)")
            # if _shape(self.wk.weight) != exp_kv:
            #     raise RuntimeError(f"[K shape] { _shape(self.wk.weight) } != {exp_kv} "
            #                     f"(likely manifest q/k/v mapping issue)")
            # if _shape(self.wv.weight) != exp_kv:
            #     raise RuntimeError(f"[V shape] { _shape(self.wv.weight) } != {exp_kv} "
            #                     f"(likely manifest q/k/v mapping issue)")   
            
            _check_or_defer(self.wq.weight, exp_q,  "Q")
            _check_or_defer(self.wk.weight, exp_kv, "K")
            _check_or_defer(self.wv.weight, exp_kv, "V")

            # ---- Device alignment (no synchronous fallback) ----
            dev = self.wq.weight.device
            if x.device != dev:
                x = x.to(dev, non_blocking=True)
            if freqs_complex.device != dev:
                freqs_complex = freqs_complex.to(dev, non_blocking=True)

            # QKVæŠ•å½± - ä½¿ç”¨ä¸“é—¨çš„compute stream
            # compute_stream = self.streams.weight_compute if self.streams else None
            compute_stream = self.compute_stream
            qkv_start = time.time()
            if compute_stream:
                with torch.cuda.stream(compute_stream):
                    with cuda_timer("attn_us", self.layer_id):
                        # print("wq.weight.device =", self.wq.weight.device)
                        q = self.wq(x).view(bsz, seqlen, self.n_heads_q, self.head_dim)
                        if _verbose:
                            print(f"[ATTN] Layer {self.layer_id} Q projection done ({(time.time()-qkv_start)*1000:.2f}ms)")
                        k = self.wk(x).view(bsz, seqlen, self.n_kv_heads, self.head_dim)
                        if _verbose:
                            print(f"[ATTN] Layer {self.layer_id} K projection done ({(time.time()-qkv_start)*1000:.2f}ms)")
                        v = self.wv(x).view(bsz, seqlen, self.n_kv_heads, self.head_dim)
                        if _verbose:
                            print(f"[ATTN] Layer {self.layer_id} V projection done ({(time.time()-qkv_start)*1000:.2f}ms)")

                        # åº”ç”¨æ—‹è½¬ä½ç½®ç¼–ç 
                        # q = apply_rotary_embeddings(q, freqs_complex)
                        # k = apply_rotary_embeddings(k, freqs_complex)
                        q = apply_rotary_embeddings(q, freqs_complex, start_pos=start_pos)
                        k = apply_rotary_embeddings(k, freqs_complex, start_pos=start_pos)
                        if _verbose:
                            print(f"[ATTN] Layer {self.layer_id} RoPE done ({(time.time()-qkv_start)*1000:.2f}ms)")

            else:
                # å›é€€åˆ°é»˜è®¤stream
                with cuda_timer("attn_us", self.layer_id):
                    # print("wq.weight.device =", self.wq.weight.device)
                    q = self.wq(x).view(bsz, seqlen, self.n_heads_q, self.head_dim)
                    k = self.wk(x).view(bsz, seqlen, self.n_kv_heads, self.head_dim)
                    v = self.wv(x).view(bsz, seqlen, self.n_kv_heads, self.head_dim)

                    # åº”ç”¨æ—‹è½¬ä½ç½®ç¼–ç 
                    # q = apply_rotary_embeddings(q, freqs_complex)
                    # k = apply_rotary_embeddings(k, freqs_complex)
                    q = apply_rotary_embeddings(q, freqs_complex, start_pos=start_pos)
                    k = apply_rotary_embeddings(k, freqs_complex, start_pos=start_pos)
        
            # ------------------------- (A) æ¨å…¥ KV åˆ° offloader -------------------------
            bsz, seqlen, n_heads, head_dim = k.shape

            # å¯¹äºæ¯ä¸ªtokenä½ç½®, è®¡ç®—å¯¹åº”çš„blockå¹¶push
            if getattr(self, "offloader", None) is not None:
                for seq_idx in range(seqlen):
                    blk_idx   = (start_pos + seq_idx) // self.block_sz
                    token_idx =  start_pos + seq_idx

                    # ä¿æŒ (bsz, heads, dim) â€”â€” åˆ‡å‹¿ squeezeï¼Œå¦åˆ™ heads ä¼šè¢«è¯¯å½“ batch
                    k_curr = k[:, seq_idx, :, :]    # (bsz, n_kv_heads, head_dim)
                    v_curr = v[:, seq_idx, :, :]

                    # å°†è¯¥ token å†™å…¥æ‰€å± block çš„æ­£ç¡® token æ§½ä½
                    self.offloader.push(
                        layer=self.layer_id,
                        blk=blk_idx,
                        k=k_curr,
                        v=v_curr,
                        token_idx=token_idx,
                        batch_idx=batch_idx,
                    )

            # ------------------------- (B) é€‰æ‹©å¹¶å–å›éœ€è¦çš„ blocks -------------------------
            blk_idx = start_pos // self.block_sz 
        
            # è·å–Top-K blocks (å¦‚æœæœ‰ offloader)
            nvtx.range_push(f"layer_{self.layer_id}_kv_fetch")
            with cuda_timer("kv_fetch_us", self.layer_id):
                do_profile_gpu = bool(self.enable_profiling and x.is_cuda)
                if do_profile_gpu:
                    fetch_evt_start = torch.cuda.Event(enable_timing=True)
                    fetch_evt_end = torch.cuda.Event(enable_timing=True)
                    fetch_evt_start.record()

                if getattr(self, "offloader", None) is not None:
                    blocks = self.offloader.topk_blocks(self.layer_id, self.topk_blk, batch_idx=batch_idx)
                    # ä¿è¯å½“å‰ block åœ¨åˆ—è¡¨å†…
                    if blk_idx not in blocks:
                        blocks = sorted(set(blocks + [blk_idx]))
                        # ç®€å•æˆªæ–­åˆ° topkï¼Œé¿å…è¿‡åº¦å¤æ‚çš„è·ç¦»è®¡ç®—
                        if len(blocks) > self.topk_blk:
                            blocks = blocks[:self.topk_blk]
                    else:
                        blocks = sorted(blocks)
                    needed = torch.tensor(blocks, device=x.device, dtype=torch.long)
                    k_full, v_full = self.offloader.fetch(
                        self.layer_id, needed, batch_idx=batch_idx, bsz=bsz
                    )
                else:
                    # æ—  offloaderï¼šç›´æ¥ä½¿ç”¨å½“å‰åºåˆ—çª—å£ï¼ˆè½¬ä¸º (B,H,T,D)ï¼‰
                    k_full = k.transpose(1, 2).contiguous()
                    v_full = v.transpose(1, 2).contiguous()
                    blocks = [blk_idx]  # ä¸ºåç»­ update_importances æä¾› blocks åˆ—è¡¨

                if do_profile_gpu:
                    fetch_evt_end.record()
                    if not fetch_evt_end.query():
                        fetch_evt_end.synchronize()
                    self.kv_elapsed_time = fetch_evt_start.elapsed_time(fetch_evt_end) * 1000
                    PERF_TRACKER.add_layer_stat(self.layer_id, "kv_fetch_us", self.kv_elapsed_time)
                else:
                    self.kv_elapsed_time = 0
            nvtx.range_pop()  # kv_fetch

            # ============================================================
            # 3) ç¡®ä¿ KV Cacheï¼ˆå†å² K/Vï¼‰åœ¨ CUDAï¼ˆé˜²æ­¢ q åœ¨ CUDAã€k_full åœ¨ CPU çš„ bmm æŠ¥é”™ï¼‰
            # Ensure KV cache (historical K/V) is on CUDA (prevent bmm error when q is on CUDA but k_full on CPU)
            # ============================================================
            if k_full.device.type != "cuda":
                raise RuntimeError(f"Layer {self.layer_id} SelfAttention: k_full is on {k_full.device}, but q is on {q.device}. "
                                 "This would cause 'mat2 is on cpu' error in bmm. KV cache must be on CUDA.")
            if v_full.device.type != "cuda":
                raise RuntimeError(f"Layer {self.layer_id} SelfAttention: v_full is on {v_full.device}, but q is on {q.device}. "
                                 "This would cause 'mat2 is on cpu' error in bmm. KV cache must be on CUDA.")

            # å¦‚æœè®¾å¤‡ä¸ä¸€è‡´ï¼ˆä¾‹å¦‚ä¸åŒçš„ CUDA è®¾å¤‡ï¼‰ï¼Œå¼ºåˆ¶å¯¹é½åˆ° q çš„è®¾å¤‡
            # If devices mismatch (e.g., different CUDA devices), force align to q's device
            if k_full.device != q.device:
                k_full = k_full.to(q.device, non_blocking=True)
            if v_full.device != q.device:
                v_full = v_full.to(q.device, non_blocking=True)

            #  batch
            if k_full.dim() == 3:
                # (seq_len, n_heads, head_dim) -> (1, n_heads, seq_len, head_dim)
                k_full = k_full.permute(1, 0, 2).unsqueeze(0)
                v_full = v_full.permute(1, 0, 2).unsqueeze(0)
            elif k_full.dim() == 4:
                # æ£€æŸ¥æ˜¯å¦å·²ç»æ˜¯æ­£ç¡®çš„æ ¼å¼ (bsz, n_heads, seq_len, head_dim)
                # é€šè¿‡æ¯”è¾ƒ dimension sizesï¼šheads åº”è¯¥æ¯” head_dim å°
                if k_full.size(1) == self.n_kv_heads:
                    # å·²ç»æ˜¯ (bsz, n_heads, seq_len, head_dim)ï¼Œä¸éœ€è¦ transpose
                    pass
                else:
                    # å‡è®¾æ˜¯ (bsz, seq_len, n_heads, head_dim)ï¼Œéœ€è¦ transpose
                    k_full = k_full.transpose(1, 2)  # (bsz, n_heads, seq_len, head_dim)
                    v_full = v_full.transpose(1, 2)  # (bsz, n_heads, seq_len, head_dim)

            # ç¡®ä¿k_fullå’Œv_fullä¸qçš„batchç»´åº¦ä¸€è‡´
            if k_full.size(0) == 1 and bsz > 1:
                # å•batchçš„KVéœ€è¦æ‰©å±•åˆ°å¤šbatch
                k_full = k_full.expand(bsz, -1, -1, -1)
                v_full = v_full.expand(bsz, -1, -1, -1)

            k_full = k_full.to(q.dtype)
            v_full = v_full.to(q.dtype)
            # é‡å¤KVå¤´ä»¥åŒ¹é…æŸ¥è¯¢å¤´æ•°ï¼ˆä½¿ç”¨é›¶æ‹·è´è§†å›¾æ‰©å±•ï¼Œé¿å…ç‰©ç†å¤åˆ¶ï¼‰
            # if self.n_heads_q != self.n_kv_heads:
            if (self.n_heads_q != self.n_kv_heads) and (k_full.size(1) != self.n_heads_q):
                # æ—§æ–¹å¼ï¼ˆç‰©ç†å¤åˆ¶ï¼‰ï¼š
                # k_full = k_full.repeat_interleave(self.n_rep, dim=1)
                # v_full = v_full.repeat_interleave(self.n_rep, dim=1)

                # æ–°æ–¹å¼ï¼ˆé›¶æ‹·è´ï¼‰ï¼š(B,Hkv,Tk,D) -> (B,Hkv,1,Tk,D) -> (B,Hkv,n_rep,Tk,D) -> (B,Hq,Tk,D)
                k_full = k_full.unsqueeze(2).expand(-1, -1, self.n_rep, -1, -1)\
                               .reshape(bsz, self.n_heads_q, k_full.size(2), self.head_dim)
                v_full = v_full.unsqueeze(2).expand(-1, -1, self.n_rep, -1, -1)\
                               .reshape(bsz, self.n_heads_q, v_full.size(2), self.head_dim)
        
            # ç¡®ä¿ç¼“å†²åŒºè¶³å¤Ÿå¤§
            q = q.transpose(1, 2)  # (B, H, Tq, D)

            # åœ¨è¿›å…¥æ³¨æ„åŠ›è®¡ç®—å‰ä¸º workspace é¢„ç•™æ˜¾å­˜ä½™é‡
            # æ³¨æ„ï¼šä½¿ç”¨ Flash Attention åï¼Œworkspace éœ€æ±‚å¤§å¹…é™ä½ï¼ˆæ— éœ€ç‰©åŒ– [B,H,T,T]ï¼‰
            wm = getattr(self, "weight_manager", None)
            if wm is not None and hasattr(wm, "ensure_headroom_mb"):
                try:
                    # é»˜è®¤ 64 MBï¼ˆFlash Attention åªéœ€å°‘é‡ workspaceï¼‰
                    # ä¼˜å…ˆä½¿ç”¨ WSM åˆå§‹åŒ–æ—¶è¯»å–çš„å€¼ï¼Œå…¼å®¹è¿è¡Œæ—¶ç¯å¢ƒå˜é‡ä¿®æ”¹
                    extra_headroom_mb = getattr(wm, "attn_workspace_headroom_mb", 64)
                except Exception:
                    extra_headroom_mb = 64
                # é¿å…è¯¯é€å‡ºå½“å‰å±‚ attn ç»„
                excl = {(self.layer_id, "attn")}
                wm.ensure_headroom_mb(extra_headroom_mb, exclude=excl)

            # Attentionè®¡ç®— - ä½¿ç”¨compute stream
            nvtx.range_push(f"layer_{self.layer_id}_attention_compute")
            do_profile_gpu = bool(self.enable_profiling and x.is_cuda)

            # ğŸ”¥ ä½¿ç”¨ Flash Attention - ç»Ÿä¸€ä½¿ç”¨æ—§ APIï¼ˆæ›´ç¨³å®šï¼‰
            # æ³¨æ„ï¼šPyTorch 2.4+ çš„æ–° API (torch.nn.attention.sdpa_kernel) å‚æ•°ä¸åŒ
            # ä¸ºäº†å…¼å®¹æ€§ï¼Œç»Ÿä¸€ä½¿ç”¨ torch.backends.cuda.sdp_kernel
            is_causal = hasattr(self, 'apply_causal_mask') and self.apply_causal_mask
            from contextlib import nullcontext
            try:
                from torch.backends.cuda import sdp_kernel as sdpa_kernel
                # å…è®¸ math å›é€€ï¼Œé¿å…â€œæ— å¯ç”¨å†…æ ¸â€çš„ç¡¬é”™è¯¯
                sdpa_ctx = sdpa_kernel(enable_flash=True, enable_mem_efficient=True, enable_math=True)
            except Exception:
                sdpa_ctx = nullcontext()

            if compute_stream:
                with torch.cuda.stream(compute_stream):
                    with cuda_timer("attn_us", self.layer_id):
                        # mha
                        if do_profile_gpu:
                            attn_evt_start = torch.cuda.Event(enable_timing=True)
                            attn_evt_end = torch.cuda.Event(enable_timing=True)
                            attn_evt_start.record()

                        # é¿å…ç‰©åŒ– [B,H,T,T] çš„ scores/attn_weights
                        with sdpa_ctx:
                            out = torch.nn.functional.scaled_dot_product_attention(
                                q, k_full, v_full, attn_mask=None, dropout_p=0.0, is_causal=is_causal
                            )
                        # ğŸš€ ç«‹åˆ»é‡Šæ”¾ä¸å†éœ€è¦çš„ä¸­é—´æ¿€æ´»ï¼Œé™ä½å³°å€¼å†…å­˜
                        del q
                        del k
                        del v
                        del k_full
                        del v_full

                        if do_profile_gpu:
                            attn_evt_end.record()
                            if not attn_evt_end.query():
                                attn_evt_end.synchronize()
                            self.attn_time = attn_evt_start.elapsed_time(attn_evt_end) * 1000
                            PERF_TRACKER.add_layer_stat(self.layer_id, "attn_us", self.attn_time)
                        else:
                            self.attn_time = 0
            else:
                with cuda_timer("attn_us", self.layer_id):
                    # mha
                    if do_profile_gpu:
                        attn_evt_start = torch.cuda.Event(enable_timing=True)
                        attn_evt_end = torch.cuda.Event(enable_timing=True)
                        attn_evt_start.record()

                    # é¿å…ç‰©åŒ– [B,H,T,T] çš„ scores/attn_weights
                    with sdpa_ctx:
                        out = torch.nn.functional.scaled_dot_product_attention(
                            q, k_full, v_full, attn_mask=None, dropout_p=0.0, is_causal=is_causal
                        )
                    del q
                    del k
                    del v
                    del k_full
                    del v_full

                    if do_profile_gpu:
                        attn_evt_end.record()
                        if not attn_evt_end.query():
                            attn_evt_end.synchronize()
                        self.attn_time = attn_evt_start.elapsed_time(attn_evt_end) * 1000
                        PERF_TRACKER.add_layer_stat(self.layer_id, "attn_us", self.attn_time)
                    else:
                        self.attn_time = 0
            nvtx.range_pop()  # attention_compute

            # è½¬æ¢å› [B, T, H, D] æ ¼å¼
            out = out.transpose(1, 2).contiguous()

            # --- ç»Ÿè®¡ä¿¡æ¯ï¼ˆè‹¥æœ‰ï¼‰ ---
            stats = PERF_TRACKER.layer_stats.get(self.layer_id, {})
            self.kv_elapsed_time = stats.get("kv_fetch_us", 0)
            self.attn_time       = stats.get("attn_us",     0)


            feat = self.n_heads_q * self.head_dim  # = dim
            B, Tq = bsz, seqlen
            w = self.wo.weight
        
            # âš ï¸ æ³¨æ„ï¼šä½¿ç”¨ Flash Attention åï¼Œattn_weights ä¸å†ç‰©åŒ–
            # é‡è¦åº¦ç»Ÿè®¡åŠŸèƒ½å·²è¢«ç¦ç”¨ï¼Œå› ä¸º scaled_dot_product_attention ä¸è¿”å›æƒé‡çŸ©é˜µ
            # è¿™æ˜¯å†…å­˜ä¼˜åŒ–çš„é¢„æœŸè¡Œä¸ºï¼šé¿å…ç‰©åŒ– [B,H,T,T] çš„å·¨å¤§çŸ©é˜µ
            # å¦‚æœéœ€è¦ token importance ç»Ÿè®¡ï¼Œéœ€è¦ä½¿ç”¨å…¶ä»–æ–¹æ³•ï¼ˆä¾‹å¦‚æ¢¯åº¦ã€æ¢é’ˆç­‰ï¼‰
                    
                    
            # --- å½¢çŠ¶æŠ¤æ ï¼šç¡®ä¿é€å…¥ wo å‰ä¸º [B, seqlen, dim] ---

            def _as_btD_take_last(_out, B, Tq, feat):
                """æŠŠ out ç»Ÿä¸€æˆ [B, Tq, feat]ï¼›è‹¥å«ç´¯è®¡ T_totalï¼Œåˆ™ä»…å–æœ€å Tqã€‚"""
                ne = _out.numel()
                if _out.dim() == 3:
                    # e.g. [B, T?, D?]ï¼šçŸ«æ­£æœ€åä¸€ç»´ï¼Œå†è£å‰ª Tq
                    T_found = _out.size(1)
                    if _out.size(-1) != feat:
                        # ç”¨å…ƒç´ æ•°åæ¨ T_found
                        T_found = ne // (B * feat)
                        _out = _out.reshape(B, T_found, feat)
                    return _out[:, -Tq:, :]  # decode åœºæ™¯ï¼šåªå–æœ€å Tq
                elif _out.dim() == 2:
                    # e.g. [B, T_total*feat] æˆ– [B, feat]
                    C = _out.size(1)
                    if C == feat:
                        return _out.view(B, 1, feat)[:, -Tq:, :]
                    if C % feat == 0:
                        T_found = C // feat
                        return _out.view(B, T_found, feat)[:, -Tq:, :]
                    # å…œåº•ï¼šæŒ‰å…ƒç´ æ•°åæ¨
                    T_found = ne // (B * feat)
                    return _out.view(B, T_found, feat)[:, -Tq:, :]
                else:
                    # å…¶å®ƒå¼‚å¸¸ï¼šç”¨å…ƒç´ æ•°åæ¨
                    T_found = ne // (B * feat)
                    return _out.reshape(B, T_found, feat)[:, -Tq:, :]

            # å¦‚æœä¸æ˜¯æœŸæœ›å½¢çŠ¶/ç»´åº¦ï¼Œåšä¸€æ¬¡ç»Ÿä¸€çŸ«æ­£
            if out.dim() != 3 or out.size(0) != B or out.size(1) != Tq or out.size(2) != feat:
                out = _as_btD_take_last(out, B, Tq, feat)
            else:
                # æ ‡å‡†è·¯å¾„ï¼šå·²æ˜¯ [B, Tq, *]ï¼Œä½†æœ€åä¸€ç»´å¯èƒ½ä¸æ˜¯ feat
                if out.size(-1) != feat:
                    # å…ˆå°è¯•æŒ‰å…ƒç´ æ•°æ¢å¤å†è£å‰ª
                    T_found = out.numel() // (B * feat)
                    out = out.reshape(B, T_found, feat)[:, -Tq:, :]
                
            assert out.shape == (B, Tq, feat), f"out={out.shape}, B={B}, Tq={Tq}, feat={feat}"
            # --- çº¿æ€§å±‚ç¨³å®šè®¡ç®—ï¼šç»Ÿä¸€ 2D â†’ Linear â†’ 3D ---
            # å¯¹é½ dtype / device åˆ° wo.weight
            out2d = out.reshape(-1, feat)
            del out
            w = self.wo.weight
            if getattr(out2d, "is_meta", False) or (hasattr(out2d, "device") and out2d.device.type == "meta"):
                out2d = torch.zeros((B*Tq, feat), dtype=w.dtype, device=w.device)
            else:
                if out2d.dtype != w.dtype:
                    out2d = out2d.to(w.dtype)
                if out2d.device != w.device:
                    out2d = out2d.to(w.device, non_blocking=True)

            # è¾“å‡ºæŠ•å½±ï¼ˆå¯ç”¨ compute_streamï¼‰
            if compute_stream:
                with torch.cuda.stream(compute_stream):
                    res2d = self.wo(out2d)
            else:
                res2d = self.wo(out2d)
            del out2d

            result = res2d.view(B, Tq, -1).contiguous()
            del res2d

            # --- ç»Ÿè®¡æ”¶å°¾ ---
            total_time = (time.time() - start_time) * 1e6  # Î¼s
            PERF_TRACKER.add_layer_stat(self.layer_id, "total_forward_us", total_time)
            # print(f"[ATTN] Layer {self.layer_id} computation done")

            if wm and hasattr(wm, "notify_group_compute_done"):
                evt = torch.cuda.Event()
                evt.record(self.compute_stream if self.compute_stream is not None else torch.cuda.current_stream())
                wm.notify_group_compute_done(self.layer_id, "attn", evt)

            # ============================================================
            # 3.2) Eager KV Spill: åœ¨ prefill åˆ†æ”¯ç»“æŸå‰ï¼Œå°†æœ¬å±‚ç”Ÿæˆçš„ KV å¼‚æ­¥å†™å…¥ SSD
            # åœ¨ prefill é˜¶æ®µï¼ˆstart_pos==0ï¼‰ï¼Œæœ¬å±‚çš„ KV å·²ç”¨äºæ³¨æ„åŠ›è®¡ç®—ï¼Œå¯ç«‹å³ä¸‹æ”¾åˆ° SSD
            # ============================================================
            if start_pos == 0 and getattr(self, "offloader", None) is not None:
                # æŠŠæœ¬å±‚åˆšç”Ÿæˆçš„ KV è¦†ç›–åˆ°çš„ token å…¨éƒ¨ç”©åˆ° SSD
                # upto_token = start_pos + seqlen è¡¨ç¤ºå½“å‰å±‚å·²å¤„ç†åˆ°çš„ token ä½ç½®
                self.offloader.eager_spill_layer(
                    self.layer_id,
                    upto_token=start_pos + seqlen,
                    async_write=True
                )

            return result
        finally:
            # å¯¹ç§°è§£é™¤ï¼šATTN é˜¶æ®µ pin çš„é…å¯¹ FFN
            if wm is not None and hasattr(wm, "unpin_group"):
                wm.unpin_group(self.layer_id, "ffn")
            # è§£é™¤ IN_USE
            if in_use and hasattr(wm, "_unmark_group_in_use"):
                wm._unmark_group_in_use(self.layer_id, "attn")

# ---------- Optimized FeedForward ----------
class FeedForward(nn.Module):
    def __init__(self, args: ModelArgs):
        super().__init__()
        hidden_dim = int(4 * args.dim * 2 / 3)
        if args.ffn_dim_multiplier:
            hidden_dim = int(hidden_dim * args.ffn_dim_multiplier)
        hidden_dim = args.multiple_of * ((hidden_dim + args.multiple_of - 1) // args.multiple_of)

        # ä½¿ç”¨ stub é¿å…å¤§å†…å­˜åˆ†é…
        use_stub = getattr(args, "use_stub_params", False)
        if use_stub:
            # SSD streaming æ¨¡å¼ï¼šä½¿ç”¨ 0-size stub
            self.w1 = make_stub_linear(args.dim, hidden_dim, bias=False)
            self.w2 = make_stub_linear(hidden_dim, args.dim, bias=False)
            self.w3 = make_stub_linear(args.dim, hidden_dim, bias=False)
        else:
            # ä¼ ç»Ÿæ¨¡å¼ï¼šæ­£å¸¸åˆå§‹åŒ–
            _dev = getattr(args, "param_init_device", None)
            kw = ({"device": _dev} if _dev is not None else {})
            self.w1 = nn.Linear(args.dim, hidden_dim, bias=False, **kw)
            self.w2 = nn.Linear(hidden_dim, args.dim, bias=False, **kw)
            self.w3 = nn.Linear(args.dim, hidden_dim, bias=False, **kw)

        self.device = args.device
        self.layer_id = -1
        self.weight_manager = None  # Will be injected by _integrate_wsm_to_layers

        self.activation_buffer = None

        # è·å–streamså¼•ç”¨
        streams = None
        try:
            import llama3.stream_mnt as stream_mnt
            streams = stream_mnt.get_streams(args.device)
        except Exception:
            pass
        self.streams = streams
       
    
    def _get_modules_dict(self):
        return {
            "w1": self.w1,
            "w2": self.w2,
            "w3": self.w3
        }
    
    def _ensure_weights_cuda(self):
        wm = self.weight_manager
        if wm is None:
            return
        compute_stream = getattr(self.streams, "compute_ffn", None)
        if hasattr(wm, "wait_group_ready"):
            wm.wait_group_ready(self.layer_id, "ffn", compute_stream=compute_stream)

    # def forward(self, x: torch.Tensor) -> torch.Tensor:
    #     # --- è®¾å¤‡å¥åº·æ£€æŸ¥ï¼ˆä¸ SelfAttention ä¸€è‡´ï¼‰ ---
    #     if x.is_cuda:
    #         try:
    #             torch.cuda.current_device()
    #         except RuntimeError as e:
    #             raise RuntimeError("CUDA context is corrupted") from e

    #     print(f"[FFN] Layer {self.layer_id} forward starting...")

    #     wm = getattr(self, "weight_manager", None)
    #     in_use = False
    #     try:
    #         # ============================================================
    #         # åªç”¨äº‹ä»¶ã€ä¸é˜»å¡ï¼šæ ‡è®°ç»„ä½¿ç”¨ + ç­‰å¾…ç»„ ready äº‹ä»¶
    #         # ============================================================
    #         if wm and hasattr(wm, "_mark_group_in_use"):
    #             wm._mark_group_in_use(self.layer_id, "ffn")
    #             in_use = True

    #         # â­ åªç”¨äº‹ä»¶ç­‰å¾…ï¼Œä¸åšåŒæ­¥é˜»å¡
    #         # åœ¨ compute_ffn æµä¸Šç­‰å¾… ffn ç»„çš„ ready äº‹ä»¶ï¼ˆéé˜»å¡å¼ï¼Œåªè®©æµä¾èµ–äº‹ä»¶ï¼‰
    #         compute_stream = getattr(self.streams, "compute_ffn", None)
    #         if wm is not None and hasattr(wm, "wait_group_ready"):
    #             wm.wait_group_ready(self.layer_id, "ffn", compute_stream=compute_stream)

    #         print(f"[FFN] Layer {self.layer_id} weights event wait done (non-blocking)")

    #         # â­â­â­ Background prefetch during FFN computeï¼ˆåç»­ D å±‚ ATTnï¼‰
    #         try:
    #             if wm is not None and hasattr(wm, "prefetch_group_async"):
    #                 D = max(1, int(os.getenv("WSM_GROUP_PREFETCH_DEPTH", "2")))
    #                 nL = getattr(wm, "n_layers", 0)
    #                 used = getattr(wm, "_gpu_group_lru", [])  # ä»…åšè½»é‡é¢„ç®—ä¼°è®¡
    #                 budget = max(0, int(os.getenv("WSM_GPU_MAX_GROUPS", "10")) - len(used) - 1)
    #                 # åªåœ¨æœ‰é¢„ç®—æ—¶æ¨è¿›é¢„å–é˜Ÿåˆ—
    #                 depth = min(D, budget) if budget > 0 else 0
    #                 for off in range(1, depth + 1):
    #                     nxt = self.layer_id + off
    #                     if nxt < nL:
    #                         wm.prefetch_group_async(nxt, "attn")
    #         except Exception as e:
    #             if getattr(wm, "verbose", False):
    #                 print(f"[FFN][L{self.layer_id}] background prefetch skipped: {e}")

    #         # --- FFN è®¡ç®— ---
    #         compute_stream = getattr(self.streams, "compute_ffn", None) 
    #         if compute_stream:
    #             with torch.cuda.stream(compute_stream):
    #                 with cuda_timer("ffn_us", self.layer_id):
    #                     gate = self.w1(x)         # (B,T,28672)
    #                     up   = self.w3(x)         # (B,T,28672)
    #                     gate = F.silu(gate, inplace=True)       # in-placeï¼šè¦†ç›– gate
    #                     up.mul_(gate)             # in-placeï¼šup ç›´æ¥å˜æˆ hidden
    #                     result  = self.w2(up)        # ä»…ä¸¤å—å¤§å¼ é‡å­˜æ´»
    #         else:
    #             with cuda_timer("ffn_us", self.layer_id):
    #                 gate = self.w1(x)         # (B,T,28672)
    #                 up   = self.w3(x)         # (B,T,28672)
    #                 gate = F.silu(gate, inplace=True)       # in-placeï¼šè¦†ç›– gate
    #                 up.mul_(gate)             # in-placeï¼šup ç›´æ¥å˜æˆ hidden
    #                 result  = self.w2(up)        # ä»…ä¸¤å—å¤§å¼ é‡å­˜æ´»

    #         # é€šçŸ¥ï¼šFFN ç»„è®¡ç®—å®Œæˆï¼ˆä¾¿äºç»„çº§ LRU æ”¶ç¼©/å›æ”¶ï¼‰
    #         if wm and hasattr(wm, "notify_group_compute_done"):
    #             evt = torch.cuda.Event()
    #             evt.record(compute_stream if compute_stream is not None else torch.cuda.current_stream())
    #             wm.notify_group_compute_done(self.layer_id, "ffn", evt)

    #         print(f"[FFN] Layer {self.layer_id} computation done")
    #         return result

    #     finally:
    #         # â­ è®¡ç®—æ”¶å°¾ï¼šè§£é™¤ FFN ç»„çš„ pinï¼ˆå¯¹ç§°äº ATTN é˜¶æ®µçš„ pinï¼‰
    #         if wm is not None and hasattr(wm, "unpin_group"):
    #             wm.unpin_group(self.layer_id, "ffn")
    #         # è§£é™¤ in_use æ ‡è®°
    #         if in_use and hasattr(wm, "_unmark_group_in_use"):
    #             wm._unmark_group_in_use(self.layer_id, "ffn")
    def forward(self, x: torch.Tensor) -> torch.Tensor:
        import torch.nn.functional as F

        if x.device.type != "cuda":
            raise RuntimeError(
                f"[FeedForward L{self.layer_id}] Input tensor must be on CUDA, got {x.device}"
            )

        # ============================================================
        # â­ å›ç»•é€šçŸ¥ + äº‹ä»¶ç­‰å¾…ï¼ˆå½»åº•ä¸å…œåº•ï¼‰
        # ============================================================
        wm = getattr(self, "weight_manager", None)

        # æ²¡æœ‰ WSM æ—¶ç›´æ¥æ‰§è¡Œè®¡ç®—
        if wm is None:
            gate = self.w1(x)
            up   = self.w3(x)
            gate = F.silu(gate, inplace=True)
            up.mul_(gate)
            del gate
            out = self.w2(up)
            del up
            return out

        in_use = False
        if hasattr(wm, "_mark_group_in_use"):
            wm._mark_group_in_use(self.layer_id, "ffn")
            in_use = True

        try:
            compute_stream = getattr(self.streams, "compute_ffn", None)

            # â­ åªç”¨äº‹ä»¶ç­‰å¾…ï¼Œä¸åšåŒæ­¥é˜»å¡
            if wm is not None and hasattr(wm, "wait_group_ready"):
                wm.wait_group_ready(self.layer_id, "ffn", compute_stream=compute_stream)

            # ---- Device alignment (no synchronous fallback) ----
            dev = self.w1.weight.device
            if x.device != dev:
                x = x.to(dev, non_blocking=True)

            # åœ¨ FFN æœŸé—´å°è¯•é¢„å–ä¸‹ä¸€å±‚ ATTN
            try:
                if hasattr(wm, "prefetch_group_async"):
                    nxt = self.layer_id + 1
                    if nxt < getattr(self, "n_layer", 1 << 30):
                        gpu_count = wm.num_gpu_groups()
                        budget    = int(getattr(wm, "gpu_max_groups", 4))
                        if gpu_count < budget:
                            wm.prefetch_group_async(nxt, "attn")
            except Exception:
                pass

            if compute_stream is not None:
                with torch.cuda.stream(compute_stream):
                    gate = self.w1(x)
                    up   = self.w3(x)
                    gate = F.silu(gate, inplace=True)
                    up.mul_(gate)
                    del gate
                    result = self.w2(up)
                    del up
            else:
                gate = self.w1(x)
                up   = self.w3(x)
                gate = F.silu(gate, inplace=True)
                up.mul_(gate)
                del gate
                result = self.w2(up)
                del up

            if hasattr(wm, "notify_group_compute_done"):
                evt = torch.cuda.Event()
                evt.record(compute_stream if compute_stream is not None else torch.cuda.current_stream())
                wm.notify_group_compute_done(self.layer_id, "ffn", evt)

            return result

        finally:
            if in_use and hasattr(wm, "_unmark_group_in_use"):
                wm._unmark_group_in_use(self.layer_id, "ffn")


# ---------- Optimized EncoderBlock ----------
class EncoderBlock(nn.Module):
    def __init__(self, args: ModelArgs, layer_id: int):
        super().__init__()
        self.layer_id = layer_id
        self.n_layer = args.n_layers

        self.attention_norm = RMSNorm(args.dim, eps=args.norm_eps)
        self.ffn_norm = RMSNorm(args.dim, eps=args.norm_eps)

        self.attention = SelfAttention(args)
        self.feed_forward = FeedForward(args)

        self.attention.layer_id = layer_id
        self.feed_forward.layer_id = layer_id

        if layer_id < args.n_layers - 1:
            self.attention._next_layer_modules = self.feed_forward._get_modules_dict()

        self.forward_count = 0
        self.total_forward_time = 0.0

        self.weight_manager = None

        # è·å–streamså¼•ç”¨ç”¨äºåŒæ­¥
        self.device = args.device
        streams = None
        try:
            import llama3.stream_mnt as stream_mnt
            streams = stream_mnt.get_streams(args.device)
        except Exception:
            pass
        self.streams = streams

        # ç”¨äºäº‹ä»¶æ± å®šæœŸæ¸…ç†çš„è®¡æ•°å™¨
        self._gc_counter = 0

    def _get_modules_dict(self):
        """æ”¶é›†æ‰€æœ‰éœ€è¦ç®¡ç†çš„æ¨¡å—ï¼ˆattention + feedforwardï¼‰"""
        mods = {}
        if hasattr(self.attention, '_get_modules_dict'):
            mods.update(self.attention._get_modules_dict())
        if hasattr(self.feed_forward, '_get_modules_dict'):
            mods.update(self.feed_forward._get_modules_dict())
        return mods
    
    def forward_async(self, x: torch.Tensor, start_pos: int, freqs_complex: torch.Tensor,
                      wait_on: Optional[torch.cuda.Event] = None) -> tuple:
        """
        è½»é‡å¼‚æ­¥ forwardï¼šåªåšäº‹ä»¶æ’é˜Ÿï¼Œè¿”å› (out, done_evt)ã€‚

        Args:
            x: è¾“å…¥æ¿€æ´»
            start_pos: åºåˆ—èµ·å§‹ä½ç½®
            freqs_complex: RoPE é¢‘ç‡
            wait_on: å¯é€‰çš„å‰ç½®äº‹ä»¶ï¼ˆä¸Šä¸€å±‚çš„ done_evtï¼‰

        Returns:
            (out, done_evt): è¾“å‡ºå¼ é‡å’Œå®Œæˆäº‹ä»¶ï¼ˆåœ¨ FFN æµä¸Šè®°å½•ï¼‰
        """
        import torch
        from llama3 import stream_mnt

        target_device = self.attention_norm.weight.device
        dtype = getattr(self, "param_dtype", torch.bfloat16)

        # è®¾å¤‡/dtype å¯¹é½ï¼ˆå°½é‡é¿å…åŒæ­¥ï¼‰
        copy_stream = None
        if x.device != target_device:
            if target_device.type == "cpu" and x.device.type == "cuda":
                logger.warning(f"Layer {self.layer_id}: Attempted to move CUDA activation to CPU. Keeping on CUDA.")
            else:
                copy_stream = torch.cuda.current_stream(device=target_device)
                x = x.to(device=target_device, dtype=dtype, non_blocking=True)
        elif x.dtype != dtype:
            x = x.to(dtype=dtype)

        freq_copy_stream = None
        if freqs_complex.device != target_device:
            if target_device.type == "cpu" and freqs_complex.device.type == "cuda":
                logger.warning(f"Layer {self.layer_id}: Attempted to move CUDA freqs to CPU. Keeping on CUDA.")
            else:
                freq_copy_stream = torch.cuda.current_stream(device=target_device)
                freqs_complex = freqs_complex.to(device=target_device, non_blocking=True)

        wm = getattr(self, "weight_manager", None)
        if wm is not None and hasattr(wm, "note_compute_advance"):
            wm.note_compute_advance(self.layer_id)

        if x.device.type != "cuda":
            raise RuntimeError(f"Layer {self.layer_id}: input activation must be on CUDA, got {x.device}")

        streams = self.streams
        device = x.device

        # -------- 1) MHAï¼šåªæŒ‚äº‹ä»¶ç­‰å¾…æƒé‡ + å¯é€‰çš„å‰ç½®äº‹ä»¶ --------
        if wm is not None and hasattr(wm, "wait_group_ready"):
            wm.wait_group_ready(self.layer_id, "attn",
                                compute_stream=getattr(streams, "compute_mha", None))

        if streams and streams.compute_mha:
            with torch.cuda.stream(streams.compute_mha):
                if copy_stream is not None:
                    streams.compute_mha.wait_stream(copy_stream)
                if freq_copy_stream is not None:
                    streams.compute_mha.wait_stream(freq_copy_stream)
                if wait_on is not None:
                    streams.compute_mha.wait_event(wait_on)
                attn_in = self.attention_norm(x)
                attn_out = self.attention(attn_in, start_pos, freqs_complex)
            mha_eid, mha_evt = stream_mnt.record_event_on(streams.compute_mha, device=device)
        else:
            if wait_on is not None:
                torch.cuda.current_stream().wait_event(wait_on)
            attn_out = self.attention(self.attention_norm(x), start_pos, freqs_complex)
            mha_eid, mha_evt = None, None

        # æ®‹å·®ï¼ˆåœ¨ MHA æµå®Œæˆåï¼‰
        if streams and streams.compute_mha and mha_evt is not None:
            with torch.cuda.device(device):
                torch.cuda.current_stream().wait_event(mha_evt)
        h = x
        h.add_(attn_out)
        del attn_out

        # -------- 2) FFNï¼šåªæŒ‚äº‹ä»¶ç­‰å¾…æƒé‡ï¼›FFN æµç­‰å¾… MHA äº‹ä»¶ --------
        if wm is not None and hasattr(wm, "wait_group_ready"):
            wm.wait_group_ready(self.layer_id, "ffn",
                                compute_stream=getattr(streams, "compute_ffn", None))

        if streams and streams.compute_ffn and mha_evt is not None:
            streams.compute_ffn.wait_event(mha_evt)

        if streams and streams.compute_ffn:
            with torch.cuda.stream(streams.compute_ffn):
                ffn_in = self.ffn_norm(h)
                ffn_out = self.feed_forward(ffn_in)
            ffn_eid, ffn_evt = stream_mnt.record_event_on(streams.compute_ffn, device=device)
        else:
            ffn_out = self.feed_forward(self.ffn_norm(h))
            ffn_eid, ffn_evt = None, None

        h.add_(ffn_out)
        del ffn_out
        out = h

        # -------- 3) ï¼ˆå¯é€‰ï¼‰é¢„å– L+1 çš„ KV çª—å£ --------
        try:
            offloader = getattr(self.attention, "offloader", None)
            kv_stream = getattr(streams, "kv_h2d", None)
            nxt = self.layer_id + 1
            if (offloader is not None) and (nxt < self.n_layer) and (kv_stream is not None):
                window = int(getattr(offloader, "block_size", 256))
                seqlen = int(x.size(1))
                blocks = offloader.plan_tail_window_blocks(start_pos, seqlen, window_tokens=window)
                if hasattr(offloader, "prefetch_blocks_async"):
                    offloader.prefetch_blocks_async(nxt, blocks, stream=kv_stream)
        except Exception:
            pass

        # -------- 4) æ¸…ç† MHA äº‹ä»¶ --------
        if mha_eid is not None:
            stream_mnt.release_event(mha_eid, device=device)

        # è¿”å›è¾“å‡ºå’Œ FFN å®Œæˆäº‹ä»¶ï¼ˆä¸åœ¨è¿™é‡Œç­‰å¾…ï¼‰
        return out, ffn_evt

    def forward(self, x: torch.Tensor, start_pos: int, freqs_complex: torch.Tensor) -> torch.Tensor:
        import torch
        from llama3 import stream_mnt

        # â­â­â­ ä¿®å¤ï¼šæ¿€æ´»åº”è¯¥è·Ÿéšæƒé‡è®¾å¤‡ï¼Œè€Œä¸æ˜¯ self.deviceï¼ˆåè€…å¯èƒ½åœ¨ OOM æ—¶è¢«æ”¹æˆ "cpu"ï¼‰
        # ä½¿ç”¨ attention_norm.weight çš„è®¾å¤‡ä½œä¸ºç›®æ ‡è®¾å¤‡ï¼ˆå› ä¸ºå®ƒæ˜¯ç¬¬ä¸€ä¸ªä¼šç”¨åˆ°çš„æƒé‡ï¼‰
        target_device = self.attention_norm.weight.device
        dtype = getattr(self, "param_dtype", torch.bfloat16)

        # åªåœ¨å¿…è¦æ—¶è¿ç§»ï¼Œä¸”å¿…é¡»ç¡®ä¿ä¸ä¼šæŠŠ CUDA æ¿€æ´»è¿ç§»åˆ° CPU
        if x.device != target_device:
            if target_device.type == "cpu" and x.device.type == "cuda":
                # è­¦å‘Šï¼šä¸åº”è¯¥æŠŠ CUDA æ¿€æ´»è¿ç§»åˆ° CPU
                logger.warning(f"Layer {self.layer_id}: Attempted to move CUDA activation to CPU. Keeping on CUDA.")
            else:
                x = x.to(device=target_device, dtype=dtype, non_blocking=True)
        elif x.dtype != dtype:
            x = x.to(dtype=dtype)

        if freqs_complex.device != target_device:
            if target_device.type == "cpu" and freqs_complex.device.type == "cuda":
                logger.warning(f"Layer {self.layer_id}: Attempted to move CUDA freqs to CPU. Keeping on CUDA.")
            else:
                freqs_complex = freqs_complex.to(device=target_device, non_blocking=True)

        # Norm æ¨¡å—åº”è¯¥å·²ç»åœ¨æ­£ç¡®çš„è®¾å¤‡ä¸Šï¼ˆé€šè¿‡ weight streaming ç®¡ç†ï¼‰
        # å¦‚æœä¸åœ¨ï¼Œè¿™é‡Œä¹Ÿä¸éœ€è¦å¼ºåˆ¶è¿ç§»ï¼ˆå› ä¸º RMSNorm.forward ä¼šè‡ªåŠ¨å¤„ç†ï¼‰

        wm = getattr(self, "weight_manager", None)
        if wm is not None and hasattr(wm, "note_compute_advance"):
            wm.note_compute_advance(self.layer_id)

        # â­ åªæ£€æŸ¥æ¿€æ´»æ˜¯å¦åœ¨ CUDA ä¸Šï¼ˆæƒé‡å¯èƒ½åœ¨ SSD streaming æ¨¡å¼ä¸‹åŠ¨æ€åŠ è½½ï¼‰
        if x.device.type != "cuda":
            raise RuntimeError(f"Layer {self.layer_id}: input activation must be on CUDA, got {x.device}")

        streams = self.streams
        device  = x.device

        # -------- 1) MHAï¼šåªæŒ‚äº‹ä»¶ç­‰å¾…æƒé‡ â†’ compute_mha æµæ‰§è¡Œ â†’ è®°å½•äº‹ä»¶ --------
        if wm is not None and hasattr(wm, "wait_group_ready"):
            wm.wait_group_ready(self.layer_id, "attn",
                                compute_stream=getattr(streams, "compute_mha", None))

        if streams and streams.compute_mha:
            with torch.cuda.stream(streams.compute_mha):
                attn_in  = self.attention_norm(x)
                attn_out = self.attention(attn_in, start_pos, freqs_complex)
            # è®°å½• MHA å®Œæˆäº‹ä»¶
            mha_eid, mha_evt = stream_mnt.record_event_on(streams.compute_mha, device=device)
        else:
            attn_out = self.attention(self.attention_norm(x), start_pos, freqs_complex)
            mha_eid, mha_evt = None, None  # æ— ç‹¬ç«‹æµåˆ™ä¸äº§ç”Ÿå‘½åäº‹ä»¶

        # æ®‹å·®æœ€å¥½ä¹Ÿåœ¨ MHA æµå®Œæˆåå†è½åˆ°é»˜è®¤æµ
        if streams and streams.compute_mha and mha_evt is not None:
            with torch.cuda.device(device):
                torch.cuda.current_stream().wait_event(mha_evt)
        h = x
        h.add_(attn_out)
        del attn_out

        # -------- 2) FFNï¼šåªæŒ‚äº‹ä»¶ç­‰å¾…æƒé‡ï¼›FFN æµç­‰å¾… MHA äº‹ä»¶ â†’ è®¡ç®— --------
        if wm is not None and hasattr(wm, "wait_group_ready"):
            wm.wait_group_ready(self.layer_id, "ffn",
                                compute_stream=getattr(streams, "compute_ffn", None))

        if streams and streams.compute_ffn and mha_evt is not None:
            streams.compute_ffn.wait_event(mha_evt)

        if streams and streams.compute_ffn:
            with torch.cuda.stream(streams.compute_ffn):
                ffn_in   = self.ffn_norm(h)
                ffn_out  = self.feed_forward(ffn_in)
            # FFN å®Œæˆäº‹ä»¶
            ffn_eid, ffn_evt = stream_mnt.record_event_on(streams.compute_ffn, device=device)
        else:
            ffn_out = self.feed_forward(self.ffn_norm(h))
            ffn_eid, ffn_evt = None, None

        h.add_(ffn_out)
        del ffn_out
        out = h  # æœ€ç»ˆæ®‹å·®å¤ç”¨äº† x çš„å­˜å‚¨

        # -------- 3) ï¼ˆå¯é€‰ï¼‰åœ¨ FFN æœŸé—´é¢„å– L+1 çš„ KV çª—å£ --------
        try:
            offloader = getattr(self.attention, "offloader", None)
            kv_stream = getattr(streams, "kv_h2d", None)
            nxt = self.layer_id + 1
            if (offloader is not None) and (nxt < self.n_layer) and (kv_stream is not None):
                window = int(getattr(offloader, "block_size", 256))
                seqlen = int(x.size(1))
                blocks = offloader.plan_tail_window_blocks(start_pos, seqlen, window_tokens=window)
                if hasattr(offloader, "prefetch_blocks_async"):
                    offloader.prefetch_blocks_async(nxt, blocks, stream=kv_stream)
        except Exception:
            pass

        # -------- 4) åœ¨é»˜è®¤æµä¸Šç­‰å¾… FFN å®Œæˆäº‹ä»¶ï¼ˆåªäº‹ä»¶ä¾èµ–ï¼‰ï¼Œç„¶åè¿”å› --------
        if ffn_evt is not None:
            with torch.cuda.device(device):
                torch.cuda.current_stream().wait_event(ffn_evt)
            if ffn_eid is not None:
                stream_mnt.release_event(ffn_eid, device=device)
        if mha_eid is not None:
            stream_mnt.release_event(mha_eid, device=device)

        return out
    
    # def forward(self, x: torch.Tensor, start_pos: int, freqs_complex: torch.Tensor) -> torch.Tensor:
    #     forward_start = time.time()
        
    #     # dev   = self.device
    #     dev = str(self.device)
    #     if not dev.startswith("cuda"):
    #         try:
    #             dev = str(self.attention.wq.weight.device)
    #             self.device = dev  # ç¼“å­˜ï¼Œé¿å…æ¯æ¬¡åˆ¤æ–­
    #         except Exception:
    #             pass
    #     dtype = getattr(self, "param_dtype", torch.bfloat16)

    #     if x.device != dev or x.dtype != dtype:
    #         x = x.to(device=dev, dtype=dtype, non_blocking=True)
    #     if freqs_complex.device != dev or freqs_complex.dtype != dtype:
    #         freqs_complex = freqs_complex.to(device=dev,  non_blocking=True)

    #     # å‘ŠçŸ¥ WSMï¼šè®¡ç®—å‰ç§»ï¼ˆé©±åŠ¨ CPU/SSD æ»‘çª—ï¼‰
    #     wm = getattr(self, "weight_manager", None)
    #     if wm is not None and hasattr(wm, "note_compute_advance"):
    #         wm.note_compute_advance(self.layer_id)

    #     # å…¥å£é˜²å‘†ï¼šè¾“å…¥ä¸å½’ä¸€åŒ–æƒé‡å¿…é¡»åœ¨ CUDA
    #     if x.device.type != "cuda":
    #         raise RuntimeError(f"Layer {self.layer_id} EncoderBlock: input x is on {x.device}, but only CUDA is supported")
    #     if self.attention_norm.weight.device.type != "cuda":
    #         raise RuntimeError(f"Layer {self.layer_id} EncoderBlock: attention_norm on {self.attention_norm.weight.device}, must be on CUDA")
    #     if self.ffn_norm.weight.device.type != "cuda":
    #         raise RuntimeError(f"Layer {self.layer_id} EncoderBlock: ffn_norm on {self.ffn_norm.weight.device}, must be on CUDA")

    #     dev = x.device
    #     streams = self.streams

    #     nvtx.range_push(f"layer_{self.layer_id}_forward")
    #     with cuda_timer("total_forward_us", self.layer_id):

    #         # -------- MHA é˜¶æ®µï¼šåªåš"äº‹ä»¶ä¾èµ–"ï¼Œä¸å†é˜»å¡ ensure -----------
    #         if wm is not None:
    #             # REMOVED: wm.ensure_group_on_gpu(self.layer_id, "attn")
    #             if streams and streams.compute_mha and hasattr(wm, "wait_group_ready"):
    #                 wm.wait_group_ready(self.layer_id, "attn", compute_stream=streams.compute_mha)  # NEW: çº¯äº‹ä»¶æŒ‚è½½
    #             elif hasattr(wm, "wait_group_ready"):
    #                 wm.wait_group_ready(self.layer_id, "attn", compute_stream=None)                # NEW

    #         nvtx.range_push(f"layer_{self.layer_id}_attention")
    #         if streams and streams.compute_mha:
    #             torch.cuda.current_stream(dev).wait_stream(streams.compute_mha)  # default ç­‰ MHA æµï¼ˆå®‰å…¨ï¼‰

    #             # â­â­â­ åœ¨è®¡ç®—æµä¸­æ‰§è¡Œ MHA
    #             with torch.cuda.stream(streams.compute_mha):
    #                 # æ³¨æ„ï¼šé¢„å–é€»è¾‘å·²ç§»è‡³ FFN é˜¶æ®µï¼ˆé¿å…é‡å¤é¢„å–å’Œ OOMï¼‰
    #                 attn_in  = self.attention_norm(x)
    #                 attn_out = self.attention(attn_in, start_pos, freqs_complex)  # åœ¨ compute_mha ä¸Šæ’é˜Ÿ
    #             # åœ¨ MHA æµè®°å½•ä¸€ä¸ªäº‹ä»¶ï¼Œä¾› FFN æµç­‰å¾…
    #             mha_eid, mha_evt = None, None
    #             try:
    #                 from llama3 import stream_mnt
    #                 mha_eid, mha_evt = stream_mnt.record_event_on(streams.compute_mha, device=dev)
    #             except Exception:
    #                 mha_evt = torch.cuda.Event()
    #                 mha_evt.record(streams.compute_mha)
    #         else:
    #             # å›é€€åˆ°é»˜è®¤æµï¼ˆä¸æ¨èï¼Œä½†ä¿è¯å¯è¿è¡Œï¼‰
    #             # æ³¨æ„ï¼šé¢„å–é€»è¾‘å·²ç§»è‡³ FFN é˜¶æ®µï¼ˆé¿å…é‡å¤é¢„å–å’Œ OOMï¼‰
    #             attn_out = self.attention(self.attention_norm(x), start_pos, freqs_complex)

    #         # åœ¨ MHA å®Œæˆä¹‹å‰ä¸è¦åœ¨é»˜è®¤æµä¸Šæ¶ˆè´¹ attn_outï¼›å…ˆåšæ®‹å·®ä¹Ÿæ”¾åˆ° MHA æµé‡Œ
    #         if streams and streams.compute_mha:
    #             with torch.cuda.stream(streams.compute_mha):
    #                 h = x + attn_out
    #         else:
    #             h = x + attn_out
    #         nvtx.range_pop()  # attention

    #         # -------- FFN é˜¶æ®µï¼šåªåš"äº‹ä»¶ä¾èµ–"ï¼ŒåŒæ—¶å‰ç½®é¢„å– L+1 çš„ ATTN --------
    #         if wm is not None:
    #             # REMOVED: wm.ensure_group_on_gpu(self.layer_id, "ffn")
    #             if streams and streams.compute_ffn and hasattr(wm, "wait_group_ready"):
    #                 wm.wait_group_ready(self.layer_id, "ffn", compute_stream=streams.compute_ffn)  # NEW: çº¯äº‹ä»¶æŒ‚è½½
    #             elif hasattr(wm, "wait_group_ready"):
    #                 wm.wait_group_ready(self.layer_id, "ffn", compute_stream=None)                # NEW

    #         # è®© FFN æµç­‰å¾… MHA äº‹ä»¶ï¼ˆåªæŒ‚äº‹ä»¶ï¼Œä¸åŒæ­¥ CPUï¼‰
    #         if streams and streams.compute_ffn and 'mha_evt' in locals():
    #             streams.compute_ffn.wait_event(mha_evt)

    #         nvtx.range_push(f"layer_{self.layer_id}_ffn")
    #         if streams and streams.compute_ffn:
    #             with torch.cuda.stream(streams.compute_ffn):

    #                 # NEW â­ åœ¨ L çš„ FFN è®¡ç®—æœŸé—´ï¼Œå¯åŠ¨ L+1 çš„ ATTN é¢„å–ï¼ˆé«˜ä¼˜å…ˆçº§/åŠ  pinï¼‰
    #                 # ä½†å…ˆæ£€æŸ¥ GPU å‰©ä½™å®¹é‡ï¼Œé¿å…è¿‡åº¦é¢„å–å¯¼è‡´ OOM
    #                 if wm is not None and hasattr(wm, "prefetch_group_async"):
    #                     nxt = self.layer_id + 1
    #                     if nxt < self.n_layer:
    #                         # é¢„ç®—æ£€æŸ¥ï¼šåªæœ‰åœ¨ GPU æœªæ»¡æ—¶æ‰é¢„å–
    #                         gpu_count = len(getattr(wm, "_gpu_group_lru", []))
    #                         gpu_limit = int(os.getenv("WSM_GPU_MAX_GROUPS", "10"))
    #                         # ç•™ 2 ä¸ªä½ç½®ç»™å½“å‰å±‚ FFN + æœªæ¥æ¸…ç†
    #                         if gpu_count + 2 < gpu_limit:
    #                             try:
    #                                 wm.prefetch_group_async(nxt, "attn", pin=True, priority="high")
    #                             except TypeError:
    #                                 # å…¼å®¹è€ç­¾å
    #                                 wm.prefetch_group_async(nxt, "attn")

    #                 # åŸ FFN è®¡ç®—
    #                 ffn_in  = self.ffn_norm(h)
    #                 ffn_out = self.feed_forward(ffn_in)   # åœ¨ compute_ffn ä¸Šæ’é˜Ÿ
    #                 out     = h + ffn_out

    #             # é»˜è®¤æµç­‰å¾… FFN å®Œæˆäº‹ä»¶ï¼ˆä»…äº‹ä»¶ï¼‰
    #             ffn_evt = torch.cuda.Event()
    #             ffn_evt.record(streams.compute_ffn)
    #             torch.cuda.current_stream(dev).wait_event(ffn_evt)
    #         else:
    #             # å›é€€åˆ°é»˜è®¤æµï¼ˆä¸æ¨èï¼Œä½†ä¿è¯å¯è¿è¡Œï¼‰
    #             # æ³¨æ„ï¼šé¢„å–é€»è¾‘å·²æ•´åˆåˆ°ä¸Šæ–¹ compute_ffn åˆ†æ”¯ï¼ˆé¿å…é‡å¤ï¼‰
    #             out = h + self.feed_forward(self.ffn_norm(h))

    #         # NEW â­ åœ¨ FFN ç»“æŸå¤„ï¼šé¢„æµ‹å¹¶é¢„æ‹‰"ä¸‹ä¸€å±‚"éœ€è¦çš„ KV blocksï¼ˆå¼‚æ­¥ H2Dï¼‰
    #         try:
    #             offloader = getattr(self.attention, "offloader", None)
    #             kv_stream = getattr(self.streams, "kv_h2d", None)
    #             nxt = self.layer_id + 1
    #             if (offloader is not None) and (nxt < self.n_layer) and (kv_stream is not None):
    #                 # window_tokensï¼šä¼˜å…ˆå– offloader.block_sizeï¼›å¦åˆ™ä½¿ç”¨ä¸€ä¸ªå®‰å…¨é»˜è®¤å€¼
    #                 window = int(getattr(offloader, "block_size", 256))
    #                 seqlen = int(x.size(1))
    #                 blocks = offloader.plan_tail_window_blocks(start_pos, seqlen, window_tokens=window)
    #                 if hasattr(offloader, "prefetch_blocks_async"):
    #                     offloader.prefetch_blocks_async(nxt, blocks, stream=kv_stream)   # äº‹ä»¶ä¼šåœ¨ KV H2D ä¸Šè®°å½•
    #                 else:
    #                     # å…¼å®¹ï¼šç”¨å·²æœ‰çš„"ä¸‹ä¸€å±‚é¢„å–"API
    #                     offloader.prefetch_for_next_layer(nxt, start_pos, seqlen, D=1)
    #         except Exception:
    #             pass

    #         nvtx.range_pop()  # ffn

    #         # æ¸…ç† MHA äº‹ä»¶
    #         if streams and streams.compute_mha and 'mha_eid' in locals() and mha_eid is not None:
    #             try:
    #                 from llama3 import stream_mnt
    #                 stream_mnt.release_event(mha_eid, device=dev)
    #             except Exception:
    #                 pass

    #     nvtx.range_pop()  # layer_forward

    #     self.forward_count += 1
    #     self.total_forward_time += time.time() - forward_start

    #     # å‘¨æœŸæ€§ GC äº‹ä»¶æ± 
    #     self._gc_counter += 1
    #     if self._gc_counter % 10 == 0:
    #         try:
    #             from llama3 import stream_mnt
    #             stream_mnt.gc_event_pool(device=dev, force=False)
    #         except Exception:
    #             pass

    #     return out

    
    # def forward_async(self, x: torch.Tensor, start_pos: int, freqs_complex: torch.Tensor):
    #     """
    #     å¼‚æ­¥å‰å‘ï¼šç«‹å³è¿”å› Futureï¼Œä¸é˜»å¡è°ƒç”¨çº¿ç¨‹ã€‚
    #     è¯­ä¹‰ç­‰ä»·äº forward()ï¼Œä½†å†…éƒ¨æŠŠ MHA/FFN æ”¾åœ¨å„è‡ª compute æµï¼Œå¹¶ä»…ç”¨"äº‹ä»¶"å»ºç«‹ä¾èµ–ã€‚

    #     Returns:
    #         Future[torch.Tensor]: å¼‚æ­¥ç»“æœï¼Œè°ƒç”¨ .result() æ—¶ä¼šç­‰å¾…è®¡ç®—å®Œæˆ
    #     """
    #     from concurrent.futures import Future

    #     # ---- è®¾å¤‡ä¸ dtype åè°ƒï¼ˆå¤ç”¨ forward() é‡Œçš„é€»è¾‘ï¼‰----
    #     dev = str(self.device)
    #     if not dev.startswith("cuda"):
    #         try:
    #             dev = str(self.attention.wq.weight.device)
    #             self.device = dev
    #         except Exception:
    #             pass
    #     dtype = getattr(self, "param_dtype", torch.bfloat16)

    #     if x.device != dev or x.dtype != dtype:
    #         x = x.to(device=dev, dtype=dtype, non_blocking=True)
    #     if freqs_complex.device != dev or freqs_complex.dtype != dtype:
    #         freqs_complex = freqs_complex.to(device=dev, non_blocking=True)

    #     # ---- é€šçŸ¥ WSMï¼šæ¨è¿› CPU çª—å£ï¼ˆæ»šåŠ¨æ¨¡å¼/ç¯å½¢çª—ä¸‹ç«‹å³å…¥é˜Ÿç¼ºå¤±å±‚ï¼‰----
    #     wm = getattr(self, "weight_manager", None)
    #     if wm is not None:
    #         # è½»æ¨è¿›ï¼šåˆ·æ–°ä¿ç•™/PD çª—å£
    #         if hasattr(wm, "note_compute_advance"):
    #             wm.note_compute_advance(self.layer_id)  # è½»é‡æ›´æ–°+çª—å£ä¼°è®¡
    #         # å¼ºæ¨è¿›ï¼šæŠŠç¼ºå¤±å±‚å…¥é˜Ÿåˆ° CPU é¢„å–çº¿ç¨‹ï¼ˆä¸åœ¨å½“å‰çº¿ç¨‹åš SSD åŒæ­¥ IOï¼‰
    #         if hasattr(wm, "_advance_cpu_window_by_compute"):
    #             wm._advance_cpu_window_by_compute(self.layer_id)

    #     streams = getattr(self, "streams", None)
    #     compute_mha = getattr(streams, "compute_mha", None) if streams else None
    #     compute_ffn = getattr(streams, "compute_ffn", None) if streams else None

    #     # ---- 1) åœ¨ compute_mha ä¸Šæ’ MHAï¼Œå¹¶è®°å½•äº‹ä»¶ ----
    #     if wm is not None:
    #         # ä¿ç•™ ensure_group_on_gpu ä»¥ç¡®ä¿æƒé‡å·²åŠ è½½
    #         if hasattr(wm, "ensure_group_on_gpu"):
    #             wm.ensure_group_on_gpu(self.layer_id, "attn")
    #         if hasattr(wm, "wait_group_ready"):   # çº¯äº‹ä»¶ä¾èµ–ï¼Œç»ä¸ CPU åŒæ­¥
    #             wm.wait_group_ready(self.layer_id, "attn", compute_stream=compute_mha)

    #     if compute_mha:
    #         with torch.cuda.stream(compute_mha):
    #             attn_in  = self.attention_norm(x)
    #             attn_out = self.attention(attn_in, start_pos, freqs_complex)
    #             h = x + attn_out
    #             mha_done = torch.cuda.Event()
    #             mha_done.record(compute_mha)
    #     else:
    #         attn_in  = self.attention_norm(x)
    #         attn_out = self.attention(attn_in, start_pos, freqs_complex)
    #         h = x + attn_out
    #         mha_done = torch.cuda.Event()
    #         mha_done.record(torch.cuda.current_stream())

    #     # ---- è¶ MHA/FFN è¿›è¡Œæ—¶ï¼Œå¼‚æ­¥é¢„å–åç»­ç»„ï¼ˆL+1 çš„ attn ç­‰ï¼‰----
    #     try:
    #         if wm is not None and hasattr(wm, "prefetch_group_async"):
    #             nxt = self.layer_id + 1
    #             if nxt < self.n_layer:
    #                 # é¢„ç®—æ£€æŸ¥ï¼šé¿å… OOM
    #                 gpu_count = len(getattr(wm, "_gpu_group_lru", []))
    #                 gpu_limit = int(os.getenv("WSM_GPU_MAX_GROUPS", "10"))
    #                 if gpu_count + 2 < gpu_limit:
    #                     wm.prefetch_group_async(nxt, "attn")   # ä¸‹ä¸€å±‚ATTN
    #     except Exception:
    #         pass

    #     # ---- 2) åœ¨ compute_ffn ä¸Šæ’ FFNï¼Œç­‰å¾… MHA äº‹ä»¶ ----
    #     if wm is not None:
    #         if hasattr(wm, "ensure_group_on_gpu"):
    #             wm.ensure_group_on_gpu(self.layer_id, "ffn")
    #         if hasattr(wm, "wait_group_ready"):
    #             wm.wait_group_ready(self.layer_id, "ffn", compute_stream=compute_ffn)

    #     if compute_ffn:
    #         with torch.cuda.stream(compute_ffn):
    #             compute_ffn.wait_event(mha_done)
    #             ffn_in  = self.ffn_norm(h)
    #             ffn_out = self.feed_forward(ffn_in)
    #             out     = h + ffn_out
    #             ffn_done = torch.cuda.Event()
    #             ffn_done.record(compute_ffn)
    #     else:
    #         torch.cuda.current_stream().wait_event(mha_done)
    #         ffn_in  = self.ffn_norm(h)
    #         ffn_out = self.feed_forward(ffn_in)
    #         out     = h + ffn_out
    #         ffn_done = torch.cuda.Event()
    #         ffn_done.record(torch.cuda.current_stream())

    #     # ---- 3) åœ¨ FFN å°¾éƒ¨é¢„å–ä¸‹ä¸€å±‚çš„ KVï¼ˆå¯é€‰ï¼šä»…è§£ç é˜¶æ®µæœ‰æ•ˆï¼‰----
    #     try:
    #         offloader = getattr(self.attention, "offloader", None)
    #         kv_stream = getattr(self.streams, "kv_h2d", None)
    #         nxt = self.layer_id + 1
    #         if (offloader is not None) and (nxt < self.n_layer) and (kv_stream is not None):
    #             window = int(getattr(offloader, "block_size", 256))
    #             seqlen = int(x.size(1))
    #             blocks = offloader.plan_tail_window_blocks(start_pos, seqlen, window_tokens=window)
    #             if hasattr(offloader, "prefetch_blocks_async"):
    #                 offloader.prefetch_blocks_async(nxt, blocks, stream=kv_stream)
    #     except Exception:
    #         pass

    #     # ---- 4) è¿”å› Futureï¼šåœ¨ä¸€ä¸ªè½»çº¿ç¨‹é‡ŒæŠŠ"é»˜è®¤æµç­‰å¾…FFNäº‹ä»¶ + set_result"åšå®Œ ----
    #     fut: Future = _get_executor().submit(self._finalize_and_return,
    #                                          out, ffn_done, dev)
    #     return fut

    def _finalize_and_return(self, out_tensor: torch.Tensor, done_evt: torch.cuda.Event, device: str):
        """
        åœ¨ä¸€ä¸ªçº¿ç¨‹é‡ŒæŠŠé»˜è®¤æµä¸ FFN å®Œæˆäº‹ä»¶å»ºç«‹ä¾èµ–ï¼Œç„¶åè¿”å› out_tensorã€‚
        è¿™æ ·è°ƒç”¨è€…åœ¨æ‹¿åˆ° Future æ—¶ä»æ˜¯éé˜»å¡çš„ï¼›çœŸæ­£çš„"ç»“æœå°±ç»ª"ç”±äº‹ä»¶ä¿è¯ã€‚
        """
        with torch.cuda.device(device):
            cur = torch.cuda.current_stream()
            cur.wait_event(done_evt)  # äº‹ä»¶ä¾èµ–ï¼Œé CPU åŒæ­¥
        return out_tensor

    def get_performance_stats(self) -> Dict:
        avg_time = self.total_forward_time / max(self.forward_count, 1) * 1000  # ms
        return {
            "layer_id": self.layer_id,
            "forward_count": self.forward_count,
            "total_time_ms": self.total_forward_time * 1000,
            "avg_time_ms": avg_time,
            "detailed_stats": PERF_TRACKER.layer_stats.get(self.layer_id, {})
        }

# ---------- Utility functions ----------
def get_global_performance_stats() -> Dict:
    return PERF_TRACKER.get_stats()

def reset_performance_stats():
    PERF_TRACKER.reset()

def optimize_layer_execution_order(layers: List[EncoderBlock]) -> List[int]:
    layer_stats = [(i, layer.get_performance_stats()["avg_time_ms"]) 
                   for i, layer in enumerate(layers)]
    
    layer_stats.sort(key=lambda x: x[1])
    return [layer_id for layer_id, _ in layer_stats]
