import torch
import torch.nn as nn
from collections import OrderedDict
from typing import Dict, List, Optional
import time
import json
from .stream_mnt import get_streams

# NVTX profiling support
try:
    import torch.cuda.nvtx as nvtx
    NVTX_AVAILABLE = True
except ImportError:
    NVTX_AVAILABLE = False
    # Fallback no-op functions
    class nvtx:
        @staticmethod
        def range_push(name): pass
        @staticmethod
        def range_pop(): pass

def _pinned_clone_cpu(t: torch.Tensor) -> torch.Tensor:
    x = t.detach().cpu().contiguous()
    try:
        x = x.pin_memory()
    except Exception:
        pass
    return x

def _collect_block_modules(block: nn.Module) -> Dict[str, nn.Module]:
    """
    æ”¶é›† block ä¸­æ‰€æœ‰éœ€è¦æµå¼ç®¡ç†çš„æ¨¡å—ï¼š
    1. attention å’Œ feed_forward çš„å­æ¨¡å—ï¼ˆé€šè¿‡ _get_modules_dictï¼‰
    2. norm å±‚ï¼ˆattn_norm, ffn_normï¼‰- è¿™äº›æ˜¯å°æƒé‡ï¼Œé€‚åˆå¸¸é©» GPU
    3. è‹¥éƒ½ä¸å­˜åœ¨ï¼Œåˆ™é€€åŒ–ä¸ºæŠŠæ•´ä¸ª block è§†ä¸ºä¸€ä¸ªæ¨¡å—æ•´ä½“æ¬è¿
    """
    mods: Dict[str, nn.Module] = {}
    
    # æ”¶é›† attention å­æ¨¡å—
    if hasattr(block, "attention") and hasattr(block.attention, "_get_modules_dict"):
        try:
            mods.update(block.attention._get_modules_dict())
        except Exception:
            pass
    
    # æ”¶é›† feed_forward å­æ¨¡å—        
    if hasattr(block, "feed_forward") and hasattr(block.feed_forward, "_get_modules_dict"):
        try:
            mods.update(block.feed_forward._get_modules_dict())
        except Exception:
            pass
    
    # æ”¶é›† norm å±‚ï¼ˆå°æƒé‡ï¼Œé€‚åˆå¸¸é©» GPUï¼‰
    norm_modules = {}
    for norm_name in ["attn_norm", "ffn_norm", "attention_norm", "ffn_norm_pre", "ffn_norm_post"]:
        if hasattr(block, norm_name):
            norm_module = getattr(block, norm_name)
            if isinstance(norm_module, nn.Module):
                norm_modules[f"norm_{norm_name}"] = norm_module
    
    if norm_modules:
        mods.update(norm_modules)
    
    # å…œåº•ï¼šè‹¥æ²¡æœ‰æ”¶é›†åˆ°ä»»ä½•æ¨¡å—ï¼ŒæŠŠæ•´ä¸ª block æ¬è¿
    if not mods:
        mods["__block__"] = block
    
    return mods

class WeightStreamingManager:
    """
    æƒé‡æµå¼ç®¡ç†å™¨ï¼ˆæœ€å°ä¾µå…¥ï¼‰ï¼š
      - CPU å¸¸é©»ä¸»å‰¯æœ¬pinned,GPU ä»…æŒ‰å±‚ä¸´æ—¶æ‹·è´
      - è¿›å…¥å±‚ i å‰:ensure_on_gpu(i) + wait_stream
      - å±‚å†…ï¼šå¼‚æ­¥é¢„å– i+1 .. i+prefetch_distance(ä¸ç­‰å¾…)
      - LRU: æœ€å¤šä¿ç•™ max_cached_layers å±‚åœ¨ GPU;é€å‡ºä¸D2H,åªæŒ‡é’ˆåˆ‡å›CPUä¸»å‰¯æœ¬
    ç”¨æ³•ï¼š
        wsm = WeightStreamingManager(model, device="cuda", prefetch_distance=1, max_cached_layers=4)
        # åˆ›å»ºåç«‹åˆ»ç”Ÿæ•ˆ(å®‰è£…äº†æ¯å±‚ forward_pre_hook)
    """
    def __init__(self,
                 model: nn.Module,
                 device: str = "cuda",
                 prefetch_distance: int = 1,
                 max_cached_layers: int = 4,
                 layers_attr: str = "layers",
                 warmup_layers: int = 1,
                 verbose: bool = False,
                 monitor_fragmentation: bool = False):
        assert torch.cuda.is_available(), "CUDA not available"
        self.device = device
        self.verbose = verbose
        self.streams = get_streams(device)
        self.prefetch_distance = int(prefetch_distance)
        self.max_cached_layers = int(max_cached_layers)
        
        # å†…å­˜ç¢ç‰‡åŒ–ç›‘æ§
        self.monitor_fragmentation = monitor_fragmentation
        self.memory_stats = []
        self.fragmentation_threshold = 0.3  # 30%ç¢ç‰‡åŒ–é˜ˆå€¼

        # æ‰¾åˆ° block åˆ—è¡¨
        blocks: Optional[List[nn.Module]] = None
        if hasattr(model, "layer_infos"):
            try:
                blocks = [info["block"] for info in getattr(model, "layer_infos")]
            except Exception:
                blocks = None
        if blocks is None and hasattr(model, layers_attr):
            blocks = list(getattr(model, layers_attr))
        if not blocks:
            # æœ€åå…œåº•ï¼šä» children é‡Œæ‰¾ä¸€ä¸ªæœ€é•¿çš„é¡ºåºå®¹å™¨
            cands = []
            for _name, child in model.named_children():
                if isinstance(child, (nn.Sequential, nn.ModuleList)):
                    cands.append(list(child))
            blocks = max(cands, key=len) if cands else []
        if not blocks:
            raise RuntimeError("Cannot locate transformer blocks (layers) on model.")

        self.blocks: List[nn.Module] = blocks
        # æ¯å±‚éœ€è¦æ¬è¿çš„æ¨¡å—é›†åˆ
        self.block_mods: Dict[int, Dict[str, nn.Module]] = {
            i: _collect_block_modules(b) for i, b in enumerate(self.blocks)
        }

        # CPU ä¸»å‰¯æœ¬ï¼šparam_id -> pinned cpu tensor
        self.cpu_stash: Dict[int, torch.Tensor] = {}
        # å“ªäº›å±‚å½“å‰åœ¨ GPUï¼ˆLRUï¼Œå€¼æ— ç”¨ï¼‰
        self.gpu_cache: "OrderedDict[int, None]" = OrderedDict()
        self.layer_events: Dict[int, torch.cuda.Event] = {}

        # å®‰è£… forward_pre_hookï¼šç¡®ä¿å½“å‰å±‚ + é¢„å–åç»­
        for i, blk in enumerate(self.blocks):
            blk.register_forward_pre_hook(self._pre_hook_factory(i))

        # å°† norm å±‚ç§»åˆ° GPU å¹¶å¸¸é©»ï¼ˆè¿™äº›æ˜¯å°æƒé‡ï¼‰
        self._setup_resident_norms()
        
        # ï¼ˆå¯é€‰ï¼‰é¢„çƒ­å‰å‡ å±‚ï¼Œé™ä½ç¬¬ 0 å±‚ç­‰å¾…
        if warmup_layers > 0:
            warm = list(range(min(warmup_layers, len(self.blocks))))
            self.prefetch(warm)
            if self.verbose:
                print(f"[WSM] warmup prefetch: {warm}")

    def _setup_resident_norms(self):
        """å°† norm å±‚ç§»åˆ° GPU å¹¶å¸¸é©»ï¼ˆè¿™äº›æ˜¯å°æƒé‡ï¼Œä¸éœ€è¦æµå¼ä¼ è¾“ï¼‰"""
        if self.verbose:
            print("[WSM] Setting up resident norm layers...")
            
        norm_count = 0
        for layer_id, modules_dict in self.block_mods.items():
            for module_name, module in modules_dict.items():
                # å¦‚æœæ˜¯ norm æ¨¡å—ï¼Œç§»åˆ° GPU å¹¶ä»æµå¼ç®¡ç†ä¸­æ’é™¤
                if module_name.startswith("norm_"):
                    try:
                        module.to(self.device)
                        norm_count += 1
                        if self.verbose:
                            print(f"[WSM] Layer {layer_id}: {module_name} -> {self.device} (resident)")
                    except Exception as e:
                        if self.verbose:
                            print(f"[WSM] Warning: Failed to move {module_name} to {self.device}: {e}")
        
        if self.verbose:
            print(f"[WSM] {norm_count} norm layers set as resident on GPU")

    # ============ åŸºå…ƒï¼šå‚æ•°/æ¨¡å—çš„ CPU/GPU åˆ‡æ¢ ============

    def _record_layer_ready_event(self, idx: int):
        """åœ¨æƒé‡H2Dæµä¸Šè®°å½•ï¼šè¯¥å±‚æƒé‡æ‹·è´å·²å…¨éƒ¨æ’é˜Ÿåçš„äº‹ä»¶"""
        if not torch.cuda.is_available() or getattr(self.streams, "weight_h2d", None) is None:
            return
        evt = self.layer_events.get(idx)
        if evt is None:
            # éé˜»å¡äº‹ä»¶å³å¯ï¼›ç”¨äºè¢« compute æµ wait_event
            evt = torch.cuda.Event(blocking=False)
            self.layer_events[idx] = evt
        # åœ¨æƒé‡H2Dæµä¸Šè®°å½•äº‹ä»¶ï¼Œè¡¨ç¤ºâ€œè¯¥å±‚æ‰€æœ‰å·²æ’é˜Ÿçš„H2Då®Œæˆæ—¶è§¦å‘â€
        evt.record(self.streams.weight_h2d)

    def _wait_layer_ready(self, idx: int):
        """åœ¨å½“å‰æµä¸Šç­‰å¾…è¯¥å±‚å·²è®°å½•çš„äº‹ä»¶ï¼›è‹¥æ— äº‹ä»¶åˆ™é€€åŒ–ä¸ºæµé—´ç­‰å¾…"""
        evt = self.layer_events.get(idx)
        if evt is not None:
            torch.cuda.current_stream(self.device).wait_event(evt)
        else:
            # å…œåº•ï¼šå¦‚æœè¿˜æ²¡è®°å½•äº‹ä»¶ï¼Œå°±é€€åŒ–ä¸ºç­‰å¾…æƒé‡æµ
            self.streams.wait_weight_ready_on_current(self.device)

    def _ensure_param_cpu_stash_inplace(self, p: torch.nn.Parameter):
        """æŠŠ p.data åŸåœ°ç½®æ¢ä¸º pinned CPU ä¸»å‰¯æœ¬ï¼Œå¹¶è®°å½•åˆ° cpu_stashã€‚é¿å… DRAM åŒæŒã€‚"""
        pid = id(p)
        if pid in self.cpu_stash:
            return
        pinned = _pinned_clone_cpu(p.data)
        p.data = pinned               # ç½®æ¢ï¼šåŸCPUå¼ é‡é‡Šæ”¾
        self.cpu_stash[pid] = p.data  # è®°å½•ä¸»å‰¯æœ¬ï¼ˆå°±æ˜¯ç°åœ¨çš„ p.dataï¼‰

    def _ensure_param_on_gpu(self, p: torch.nn.Parameter):
        """ä»ä¸»å‰¯æœ¬ï¼ˆpinned CPUï¼‰H2D åˆ° GPUï¼Œå¹¶æŠŠ p.data åˆ‡åˆ° GPU å¼ é‡ï¼ˆåœ¨é«˜ä¼˜å…ˆçº§æµä¸Šï¼‰ã€‚"""
        nvtx.range_push("param_h2d")
        if p.device.type != "cpu":
            nvtx.range_pop()
            return
        pid = id(p)
        
        nvtx.range_push("ensure_cpu_stash")
        self._ensure_param_cpu_stash_inplace(p)
        nvtx.range_pop()  # ensure_cpu_stash
        
        nvtx.range_push("weight_h2d_stream")
        with torch.cuda.stream(self.streams.weight_h2d):
            nvtx.range_push("cpu_to_gpu_transfer")
            p_gpu = self.cpu_stash[pid].to(self.device, non_blocking=True)
            nvtx.range_pop()  # cpu_to_gpu_transfer
        nvtx.range_pop()  # weight_h2d_stream
        
        p.data = p_gpu  # åˆ‡åˆ° GPU
        nvtx.range_pop()  # param_h2d

    def _evict_param_to_cpu(self, p: torch.nn.Parameter):
        """é€å‡ºï¼šä¸åš D2Hï¼Œp.data ç›´æ¥æŒ‡å› cpu_stashï¼ˆCPU ä¸»å‰¯æœ¬ï¼‰ã€‚"""
        pid = id(p)
        if pid in self.cpu_stash:
            p.data = self.cpu_stash[pid]

    def _ensure_module_on_gpu(self, m: nn.Module):
        for p in m.parameters(recurse=True):
            self._ensure_param_on_gpu(p)
        for b in m.buffers(recurse=True):
            if b.device.type == "cpu":
                with torch.cuda.stream(self.streams.weight_h2d):
                    b_gpu = b.detach().to(self.device, non_blocking=True)
                try:
                    b.data = b_gpu
                except Exception:
                    pass

    def _evict_module_to_cpu(self, m: nn.Module):
        for p in m.parameters(recurse=True):
            self._evict_param_to_cpu(p)
        for b in m.buffers(recurse=True):
            if b.device.type != "cpu":
                try:
                    b_cpu = b.detach().cpu()
                    try:
                        b_cpu = b_cpu.pin_memory()
                    except Exception:
                        pass
                    b.data = b_cpu
                except Exception:
                    pass

    # ============ å±‚çº§ï¼šensure / prefetch / evict ============

    def _pre_hook_factory(self, idx: int):
        def _pre_hook(_module, _inputs):
            # 1) ç¡®ä¿æœ¬å±‚åœ¨ GPU
            self.ensure_on_gpu(idx, wait=True)
            # 2) é¢„å–åç»­è‹¥å¹²å±‚ï¼ˆä¸ç­‰å¾…ï¼Œé‡å  H2D ä¸ computeï¼‰
            if self.prefetch_distance > 0:
                nxt = [j for j in range(idx + 1, min(idx + 1 + self.prefetch_distance, len(self.blocks)))]
                self.prefetch(nxt)
        return _pre_hook

    def ensure_on_gpu(self, idx: int, wait: bool):
        nvtx.range_push(f"ensure_layer_{idx}")
        self._record_memory_stats(f"ensure_start", idx)
        
        if idx in self.gpu_cache:
            nvtx.range_push(f"cache_hit_layer_{idx}")
            self.gpu_cache.move_to_end(idx)
            # å‘½ä¸­ä¹Ÿå¯èƒ½è¿˜æ˜¯é¢„å–ä¸­çš„å±‚ï¼Œéœ€è¦æŒ‰å±‚äº‹ä»¶æ¥ç²¾ç¡®ç­‰å¾…
            if wait:
                nvtx.range_push(f"wait_layer_{idx}")
                self._wait_layer_ready(idx)
                nvtx.range_pop()  # wait_layer
            nvtx.range_pop()  # cache_hit
        else:
            nvtx.range_push(f"cache_miss_layer_{idx}")
            
            while len(self.gpu_cache) >= self.max_cached_layers:
                old, _ = self.gpu_cache.popitem(last=False)
                nvtx.range_push(f"evict_layer_{old}")
                self._record_memory_stats(f"evict_start", old)
                self._evict_layer_to_cpu(old)
                self._record_memory_stats(f"evict_end", old)
                nvtx.range_pop()  # evict
                
            # H2D å½“å‰å±‚ï¼ˆé€æ¨¡å—å‘èµ·H2Dï¼‰
            nvtx.range_push(f"h2d_transfer_layer_{idx}")
            self._record_memory_stats(f"h2d_start", idx)
            for module_name, mod in self.block_mods[idx].items():
                if not module_name.startswith("norm_"):  # è·³è¿‡å¸¸é©»çš„normæ¨¡å—
                    nvtx.range_push(f"h2d_{module_name}")
                    self._ensure_module_on_gpu(mod)
                    nvtx.range_pop()  # h2d_module
            self._record_memory_stats(f"h2d_end", idx)
            nvtx.range_pop()  # h2d_transfer
            
            self.gpu_cache[idx] = None
            # å…³é”®ï¼šæ‰€æœ‰è¯¥å±‚çš„H2Då·²æ’é˜Ÿåï¼Œè®°å½•"è¯¥å±‚å°±ç»ªäº‹ä»¶"
            nvtx.range_push(f"record_event_layer_{idx}")
            self._record_layer_ready_event(idx)
            nvtx.range_pop()  # record_event

            if self.verbose:
                print(f"[WSM] ->GPU layer={idx}")
            if wait:
                nvtx.range_push(f"wait_layer_{idx}")
                self._wait_layer_ready(idx)
                nvtx.range_pop()  # wait_layer
                
            nvtx.range_pop()  # cache_miss
        
        self._record_memory_stats(f"ensure_end", idx)
        nvtx.range_pop()  # ensure_layer


    def prefetch(self, ids: List[int]):
        if not ids:
            return
        nvtx.range_push(f"prefetch_layers_{ids}")
        
        for idx in ids:
            nvtx.range_push(f"prefetch_layer_{idx}")
            
            if idx in self.gpu_cache:
                nvtx.range_push(f"prefetch_cache_hit_{idx}")
                self.gpu_cache.move_to_end(idx)
                # å‘½ä¸­é¢„å–å°±ä¸å†é‡å¤H2Dï¼›å¯èƒ½å·²ç»æœ‰äº‹ä»¶äº†ï¼Œæ— éœ€æ“ä½œ
                nvtx.range_pop()  # prefetch_cache_hit
                nvtx.range_pop()  # prefetch_layer
                continue
                
            nvtx.range_push(f"prefetch_cache_miss_{idx}")
            while len(self.gpu_cache) >= self.max_cached_layers:
                old, _ = self.gpu_cache.popitem(last=False)
                nvtx.range_push(f"prefetch_evict_{old}")
                self._evict_layer_to_cpu(old)
                nvtx.range_pop()  # prefetch_evict
                
            nvtx.range_push(f"prefetch_h2d_layer_{idx}")
            for module_name, mod in self.block_mods[idx].items():
                if not module_name.startswith("norm_"):  # è·³è¿‡å¸¸é©»çš„normæ¨¡å—
                    nvtx.range_push(f"prefetch_h2d_{module_name}")
                    self._ensure_module_on_gpu(mod)
                    nvtx.range_pop()  # prefetch_h2d_module
            nvtx.range_pop()  # prefetch_h2d_layer
            
            self.gpu_cache[idx] = None
            # å…³é”®ï¼šé¢„å–å±‚H2Dæ’é˜Ÿåï¼Œè®°å½•"è¯¥å±‚å°±ç»ªäº‹ä»¶"ï¼ˆä¸ç­‰å¾…ï¼‰
            nvtx.range_push(f"prefetch_record_event_{idx}")
            self._record_layer_ready_event(idx)
            nvtx.range_pop()  # prefetch_record_event

            if self.verbose:
                print(f"[WSM] prefetch layer={idx}")
                
            nvtx.range_pop()  # prefetch_cache_miss
            nvtx.range_pop()  # prefetch_layer
            
        nvtx.range_pop()  # prefetch_layers

    def _evict_layer_to_cpu(self, idx: int):
        for _name, mod in self.block_mods[idx].items():
            self._evict_module_to_cpu(mod)
        # è¯¥å±‚ä»GPUç¼“å­˜ç§»é™¤åï¼Œå¯¹åº”çš„äº‹ä»¶ä¹Ÿä¸€å¹¶æ¸…ç†ï¼ˆä¸‹æ¬¡ä¼šé‡æ–°åˆ›å»º/è®°å½•ï¼‰
        self.layer_events.pop(idx, None)
        if self.verbose:
            print(f"[WSM]   evict layer={idx}")

    
    # ============ å…¼å®¹ layers.py çš„æ¥å£ ============
    
    def ensure_weights_cuda(self, layer_id: int, modules: Dict[str, nn.Module], priority: bool = False):
        """
        å…¼å®¹ layers.py ä¸­ _ensure_weights_cuda çš„è°ƒç”¨
        å°†æŒ‡å®šå±‚çš„æ¨¡å—æƒé‡ç¡®ä¿åœ¨ GPU ä¸Š
        """
        if layer_id >= len(self.blocks):
            return  # è¶…å‡ºèŒƒå›´ï¼Œå¿½ç•¥
        
        # ä½¿ç”¨ç°æœ‰çš„ ensure_on_gpu é€»è¾‘
        self.ensure_on_gpu(layer_id, wait=priority)
        
        # é¢å¤–ç¡®ä¿æä¾›çš„æ¨¡å—åœ¨ GPU ä¸Šï¼ˆå¦‚æœä¸æˆ‘ä»¬ç®¡ç†çš„ä¸åŒï¼‰
        for name, module in modules.items():
            try:
                self._ensure_module_on_gpu(module)
            except Exception as e:
                if self.verbose:
                    print(f"[WSM] Warning: Failed to ensure {name} on GPU for layer {layer_id}: {e}")
    
    def prefetch_weights(self, layer_ids: List[int], modules_dict: Dict[int, Dict[str, nn.Module]] = None):
        """
        å…¼å®¹ layers.py ä¸­é¢„å–æƒé‡çš„è°ƒç”¨
        """
        self.prefetch(layer_ids)
    
    def _get_memory_info(self):
        """è·å–å½“å‰GPUå†…å­˜ä¿¡æ¯"""
        if not torch.cuda.is_available():
            return None
        
        allocated = torch.cuda.memory_allocated(self.device)
        reserved = torch.cuda.memory_reserved(self.device)
        max_allocated = torch.cuda.max_memory_allocated(self.device)
        max_reserved = torch.cuda.max_memory_reserved(self.device)
        
        memory_stats = torch.cuda.memory_stats(self.device)
        
        return {
            'timestamp': time.time(),
            'allocated_mb': allocated / 1024**2,
            'reserved_mb': reserved / 1024**2,
            'max_allocated_mb': max_allocated / 1024**2,
            'max_reserved_mb': max_reserved / 1024**2,
            'fragmentation_ratio': (reserved - allocated) / reserved if reserved > 0 else 0,
            'allocation_count': memory_stats.get('allocation.all.current', 0),
            'segment_count': memory_stats.get('segment.all.current', 0),
            'large_pool_allocated': memory_stats.get('allocated_bytes.large_pool.current', 0) / 1024**2,
            'small_pool_allocated': memory_stats.get('allocated_bytes.small_pool.current', 0) / 1024**2,
        }
    
    def _record_memory_stats(self, operation: str, layer_id: int = -1):
        """è®°å½•å†…å­˜ç»Ÿè®¡ä¿¡æ¯"""
        if not self.monitor_fragmentation:
            return
        
        info = self._get_memory_info()
        if info:
            info['operation'] = operation
            info['layer_id'] = layer_id
            self.memory_stats.append(info)
            
            # æ£€æŸ¥ç¢ç‰‡åŒ–é˜ˆå€¼
            if info['fragmentation_ratio'] > self.fragmentation_threshold:
                print(f"âš ï¸  High fragmentation detected: {info['fragmentation_ratio']:.3f} "
                      f"during {operation} (layer {layer_id})")
    
    def get_fragmentation_report(self):
        """ç”Ÿæˆç¢ç‰‡åŒ–åˆ†ææŠ¥å‘Š"""
        if not self.memory_stats:
            return {"error": "No memory statistics collected"}
        
        fragmentation_ratios = [s['fragmentation_ratio'] for s in self.memory_stats]
        segment_counts = [s['segment_count'] for s in self.memory_stats]
        
        report = {
            'total_operations': len(self.memory_stats),
            'max_fragmentation': max(fragmentation_ratios),
            'avg_fragmentation': sum(fragmentation_ratios) / len(fragmentation_ratios),
            'min_fragmentation': min(fragmentation_ratios),
            'max_segments': max(segment_counts),
            'avg_segments': sum(segment_counts) / len(segment_counts),
            'high_fragmentation_count': sum(1 for r in fragmentation_ratios if r > self.fragmentation_threshold),
            'peak_allocated_mb': max(s['allocated_mb'] for s in self.memory_stats),
            'peak_reserved_mb': max(s['reserved_mb'] for s in self.memory_stats),
        }
        
        # ä¸¥é‡ç¨‹åº¦è¯„ä¼°
        if report['max_fragmentation'] > 0.4:
            report['severity'] = 'CRITICAL'
        elif report['max_fragmentation'] > 0.3:
            report['severity'] = 'HIGH'
        elif report['max_fragmentation'] > 0.15:
            report['severity'] = 'MEDIUM'
        else:
            report['severity'] = 'LOW'
        
        return report
    
    def save_memory_stats(self, filename: str):
        """ä¿å­˜å†…å­˜ç»Ÿè®¡åˆ°æ–‡ä»¶"""
        if not self.memory_stats:
            print("âš ï¸  No memory statistics to save")
            return
        
        with open(filename, 'w') as f:
            json.dump({
                'memory_stats': self.memory_stats,
                'fragmentation_report': self.get_fragmentation_report(),
                'config': {
                    'max_cached_layers': self.max_cached_layers,
                    'prefetch_distance': self.prefetch_distance,
                    'device': self.device,
                    'fragmentation_threshold': self.fragmentation_threshold
                }
            }, f, indent=2)
        
        print(f"ğŸ’¾ Memory statistics saved to {filename}")
    
    def clear_memory_stats(self):
        """æ¸…ç©ºå†…å­˜ç»Ÿè®¡"""
        self.memory_stats.clear()
        torch.cuda.reset_peak_memory_stats(self.device)
