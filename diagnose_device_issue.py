#!/usr/bin/env python3
"""
WSM è®¾å¤‡é—®é¢˜è¯Šæ–­å·¥å…·

å¿«é€Ÿæ£€æµ‹ Weight Streaming Manager ç›¸å…³çš„è®¾å¤‡æ”¾ç½®é—®é¢˜
"""

import sys
import torch
import pathlib

def diagnose_device_issues(model_path: str, target_device: str = "cuda"):
    """è¯Šæ–­æ¨¡å‹åŠ è½½å’Œè®¾å¤‡æ”¾ç½®é—®é¢˜"""
    
    print("ğŸ” WSM Device Issue Diagnostic Tool")
    print("="*50)
    
    # æ£€æŸ¥åŸºç¡€ç¯å¢ƒ
    print(f"PyTorch version: {torch.__version__}")
    print(f"CUDA available: {torch.cuda.is_available()}")
    if torch.cuda.is_available():
        print(f"CUDA devices: {torch.cuda.device_count()}")
        print(f"Current device: {torch.cuda.current_device()}")
    
    # æ£€æŸ¥æ¨¡å‹è·¯å¾„
    ckpt_path = pathlib.Path(model_path)
    if not ckpt_path.exists():
        print(f"âŒ Model path does not exist: {model_path}")
        return False
    
    print(f"âœ… Model path exists: {model_path}")
    
    # å¯¼å…¥å¿…è¦æ¨¡å—
    try:
        sys.path.append('/home/roger/llama3_project')
        from llama3.generator import LLaMA
        print("âœ… LLaMA modules imported successfully")
    except ImportError as e:
        print(f"âŒ Failed to import LLaMA modules: {e}")
        return False
    
    # åŠ è½½æ¨¡å‹
    print("\nğŸ“¦ Loading model...")
    try:
        # å…ˆåœ¨ CPU ä¸ŠåŠ è½½
        llama = LLaMA.build(ckpt_path, load_model=True, device="cpu")
        print("âœ… Model loaded on CPU")
    except Exception as e:
        print(f"âŒ Failed to load model: {e}")
        return False
    
    # æ£€æŸ¥åˆå§‹è®¾å¤‡çŠ¶æ€
    print("\nğŸ” Checking initial device placement...")
    try:
        m = llama.model
        
        print(f"   embed_tokens: {m.embed_tokens.weight.device}")
        print(f"   norm: {m.norm.weight.device}")
        print(f"   output: {m.output.weight.device}")
        
        if hasattr(m, 'freqs_complex'):
            print(f"   freqs_complex: {m.freqs_complex.device}")
            print(f"   freqs_complex shape: {m.freqs_complex.shape}")
            print(f"   freqs_complex dtype: {m.freqs_complex.dtype}")
        else:
            print("   âš ï¸  freqs_complex not found")
        
        print(f"   First layer device: {next(m.layers[0].parameters()).device}")
        
    except Exception as e:
        print(f"âŒ Error checking initial device state: {e}")
        return False
    
    # æµ‹è¯• freqs_complex ç§»åŠ¨
    if target_device.startswith("cuda") and torch.cuda.is_available():
        print(f"\nğŸ”„ Testing freqs_complex movement to {target_device}...")
        try:
            if hasattr(m, 'freqs_complex'):
                original_device = m.freqs_complex.device
                print(f"   Original device: {original_device}")
                
                # å°è¯•ç§»åŠ¨
                m.freqs_complex = m.freqs_complex.to(target_device)
                new_device = m.freqs_complex.device
                print(f"   After movement: {new_device}")
                
                if str(new_device) == target_device:
                    print("   âœ… freqs_complex moved successfully")
                else:
                    print(f"   âŒ freqs_complex movement failed")
                    return False
            else:
                print("   âŒ freqs_complex not available for testing")
                return False
                
        except Exception as e:
            print(f"   âŒ freqs_complex movement failed: {e}")
            
            # å°è¯•é‡æ–°åˆ›å»º
            print("   ğŸ”§ Attempting to recreate freqs_complex...")
            try:
                from llama3.layers import precompute_theta_pos_frequencies
                m.freqs_complex = precompute_theta_pos_frequencies(
                    llama.args.dim // llama.args.n_heads,
                    llama.args.max_seq_len * 2,
                    device=target_device,
                    theta=llama.args.rope_theta,
                )
                print(f"   âœ… freqs_complex recreated on {target_device}")
                print(f"   New device: {m.freqs_complex.device}")
                
            except Exception as e2:
                print(f"   âŒ Failed to recreate freqs_complex: {e2}")
                return False
    
    # æµ‹è¯•ç®€å•çš„è¾“å…¥å¼ é‡åˆ›å»º
    print(f"\nğŸ§ª Testing input tensor creation on {target_device}...")
    try:
        test_tokens = torch.tensor([[1, 2, 3, 4]], device=target_device, dtype=torch.long)
        print(f"   Test tokens device: {test_tokens.device}")
        print("   âœ… Input tensor creation successful")
        
        # æµ‹è¯•ä¸ freqs_complex çš„å…¼å®¹æ€§
        if hasattr(m, 'freqs_complex'):
            freqs_slice = m.freqs_complex[0:1].to(test_tokens.device)
            print(f"   freqs_slice device: {freqs_slice.device}")
            print("   âœ… Device compatibility test passed")
        
    except Exception as e:
        print(f"   âŒ Input tensor test failed: {e}")
        return False
    
    print(f"\nâœ… All diagnostic checks passed!")
    print("   Your WSM setup should work correctly now.")
    
    return True

def main():
    import argparse
    parser = argparse.ArgumentParser(description="Diagnose WSM device issues")
    parser.add_argument("--model-path", required=True, help="Path to model")
    parser.add_argument("--device", default="cuda", help="Target device")
    
    args = parser.parse_args()
    
    success = diagnose_device_issues(args.model_path, args.device)
    sys.exit(0 if success else 1)

if __name__ == "__main__":
    main()