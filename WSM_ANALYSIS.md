# Weight Streaming Manager (WSM) å…¨é¢åˆ†ææŠ¥å‘Š

## æ¦‚è¿°

ä»è°ƒè¯•æ—¥å¿—å’Œä»£ç åˆ†ææ¥çœ‹,WSM å­˜åœ¨**ä¸¥é‡çš„æƒé‡é©»ç•™çŠ¶æ€ä¸ä¸€è‡´é—®é¢˜**,å¯¼è‡´å¤§é‡ "missing tensors" è­¦å‘Šã€‚è¿™æ˜¯ä¸€ä¸ªå…¸å‹çš„**ç«æ€æ¡ä»¶ (Race Condition)** å’Œ**çŠ¶æ€ç®¡ç†ä¸ä¸€è‡´**çš„é—®é¢˜ã€‚

---

## ğŸ”´ æ ¸å¿ƒé—®é¢˜

### 1. **"Missing Tensors" çš„æ ¹æœ¬åŸå› **

æ—¥å¿—ä¸­åå¤å‡ºç°:
```
[WSM][resident] 19.attn missing tensors: layers.19.attention.wq.weight, layers.19.attention.wk.weight, ...
[WSM][resident] 20.attn missing tensors: layers.20.attention.wq.weight, ...
```

**é—®é¢˜æ ¹æº**:
- `_group_is_resident()` æ£€æŸ¥æ—¶,æƒé‡çš„ **ready event å·²è§¦å‘**,ä½†**å‚æ•°å®é™…è¿˜æœªå®Œå…¨å¤åˆ¶åˆ° GPU**
- æˆ–è€…æƒé‡åˆšè¢«å¤åˆ¶åˆ° GPU,å°±ç«‹åˆ»è¢« `_proactive_cleanup_old_groups()` æˆ– `_shrink_gpu_groups_now()` **è¿‡æ—©é©±é€**

### 2. **ç«æ€æ¡ä»¶åˆ†æ**

#### æ—¶åºé—®é¢˜ç¤ºä¾‹:
```
æ—¶åˆ» T0: prefetch_group_async(L19, 'attn') å‘èµ·å¼‚æ­¥ H2D ä¼ è¾“
æ—¶åˆ» T1: _record_group_ready_event(L19, 'attn') åœ¨ H2D stream ä¸Šè®°å½• event
æ—¶åˆ» T2: event.record() å®Œæˆ,ä½† H2D ä¼ è¾“è¿˜åœ¨è¿›è¡Œ
æ—¶åˆ» T3: _group_events[(19,'attn')] è¢«è®¾ç½®,æ ‡è®°"å°±ç»ª"
æ—¶åˆ» T4: å¦ä¸€ä¸ªçº¿ç¨‹è°ƒç”¨ _plan_pairwise_nearest(),æ£€æµ‹åˆ° event å­˜åœ¨
æ—¶åˆ» T5: _group_is_resident(19, 'attn') è¢«è°ƒç”¨
æ—¶åˆ» T6: âŒ æ­¤æ—¶å‚æ•°è¿˜åœ¨ä¼ è¾“ä¸­,p.is_cuda=False æˆ– p.numel()=0
æ—¶åˆ» T7: æŠ¥å‘Š "missing tensors"
```

#### ä»£ç ä½ç½®: [weight_streaming_manager.py:2673-2714](llama3/weight_streaming_manager.py#L2673-L2714)

```python
def _group_is_resident(self, layer_idx: int, group: str, wait_for_event: bool = False) -> bool:
    # â­ é—®é¢˜: å³ä½¿ wait_for_event=True,è½»é‡è½®è¯¢å¯èƒ½åœ¨ä¼ è¾“å®Œæˆå‰è¿”å›
    if wait_for_event:
        evt = self._group_events.get(key)
        if evt is not None:
            while not evt.query():  # âŒ query() è¿”å› True != å‚æ•°å·²åœ¨ GPU
                time.sleep(0.001)

    # â­ å…³é”®æ£€æŸ¥ç‚¹
    for suf in suffixes:
        pname = f"layers.{layer_idx}.{suf}"
        p = self.name_to_param.get(pname)
        if (p is None) or (not p.is_cuda) or (p.numel() == 0):
            missing.append(pname)  # âŒ æŠ¥å‘Š missing
```

**æ ¹æœ¬é—®é¢˜**:
1. `event.query()` è¿”å› `True` åªä»£è¡¨ **event å·²è®°å½•**,ä¸ä»£è¡¨ **æ•°æ®å·²ä¼ è¾“å®Œæˆ**
2. `event.record(stream)` æ˜¯**å¼‚æ­¥æ“ä½œ**,è®°å½•å®Œæˆ â‰  æµä¸­æ‰€æœ‰æ“ä½œå®Œæˆ
3. éœ€è¦ `event.synchronize()` æˆ– `stream.synchronize()` æ‰èƒ½ç¡®ä¿ä¼ è¾“å®Œæˆ

---

## ğŸ” è¯¦ç»†é—®é¢˜åˆ†æ

### é—®é¢˜ 1: Event è¯­ä¹‰è¯¯ç”¨

#### å½“å‰å®ç° (é”™è¯¯):
```python
# weight_streaming_manager.py:2744-2747
evt.record(h2d)  # âš ï¸ å¼‚æ­¥è®°å½•,ç«‹å³è¿”å›
# CPU ç»§ç»­æ‰§è¡Œ,ä¸ç­‰å¾…ä¼ è¾“å®Œæˆ
```

#### æ­£ç¡®å®ç°åº”è¯¥:
```python
evt.record(h2d)
# åœ¨éœ€è¦ä½¿ç”¨æƒé‡æ—¶:
compute_stream.wait_event(evt)  # GPU ç«¯åŒæ­¥
# æˆ–
evt.synchronize()  # CPU ç«¯åŒæ­¥(é˜»å¡)
```

**å½“å‰ä»£ç çš„é—®é¢˜**:
- `_record_group_ready_event()` åªè®°å½• event,ä¸åŒæ­¥
- `_group_is_resident()` çš„ `wait_for_event` ç”¨ `evt.query()` è½®è¯¢,è€Œé `evt.synchronize()`
- å¯¼è‡´**å‡é˜³æ€§**: event å·²è§¦å‘,ä½†æ•°æ®è¿˜åœ¨ä¼ è¾“

---

### é—®é¢˜ 2: è¿‡æ—©é©±é€ (Premature Eviction)

#### ä»£ç ä½ç½®: [weight_streaming_manager.py:2874-2947](llama3/weight_streaming_manager.py#L2874-L2947)

```python
def _proactive_cleanup_old_groups(self, current_layer: int):
    # â­ é—®é¢˜: "æ—§ç»„"åˆ¤å®šè¿‡äºæ¿€è¿›
    for lyr, grp in list(self._gpu_group_ring):
        rel_pos = (lyr_int - cur_int) % self.n_layers
        # åªè¦ä¸åœ¨ [-behind, ahead] çª—å£å†…,å°±é©±é€
        if -behind <= rel_pos <= ahead:
            continue
        # âŒ å¯èƒ½é©±é€"åˆšé¢„å–å®Œæˆä½†è¿˜æœªä½¿ç”¨"çš„ç»„
        candidates.append(key)
```

**è§¦å‘åœºæ™¯**:
```
1. Layer 19 çš„ prefetch_group_async(19, 'attn') åˆšå®Œæˆ H2D
2. ç«‹å³æ‰§è¡Œ Layer 20,è§¦å‘ _proactive_cleanup_old_groups(20)
3. åˆ¤å®š Layer 19 ä¸åœ¨ [20-3, 20+4] çª—å£å†…
4. âŒ å°† Layer 19.attn é©±é€å› CPU
5. ä½† Layer 19 çš„ FFN è®¡ç®—å¯èƒ½è¿˜éœ€è¦è¿™äº›æƒé‡
```

---

### é—®é¢˜ 3: çŠ¶æ€ä¸ä¸€è‡´

#### å¤šä¸ªçŠ¶æ€æ ‡è®°äº’ç›¸å†²çª:
```python
self._gpu_group_ring = []           # GPU ä¸Šçš„ç»„ LRU
self._gpu_group_inflight = set()    # æ­£åœ¨ä¼ è¾“çš„ç»„
self._group_events = {}             # ready event è¡¨
self._group_state = {}              # çŠ¶æ€æœº: CPU/INFLIGHT/RESIDENT/EVICTING
```

**ä¸ä¸€è‡´ç¤ºä¾‹**:
```
çŠ¶æ€1: (19,'attn') in _gpu_group_inflight  âœ“
çŠ¶æ€2: _group_events[(19,'attn')] å­˜åœ¨      âœ“
çŠ¶æ€3: _group_state[(19,'attn')] = "INFLIGHT" âœ“
çŠ¶æ€4: _group_is_resident(19,'attn') = False  âŒ
```

#### ä»£ç ä½ç½®: [weight_streaming_manager.py:2848-2872](llama3/weight_streaming_manager.py#L2848-L2872)

```python
def _plan_pairwise_nearest(self, cur: int, depth: int):
    def _want(L, g):
        key = (Lw, 'attn' if g=='attn' else 'ffn')
        if self._group_is_resident(*key, wait_for_event=False):  # âŒ æœªåŒæ­¥
            return False
        if key in self._gpu_group_inflight:  # âœ“ è¿™ä¸ªæ£€æŸ¥æ˜¯å¯¹çš„
            return False
        need.append(key)
```

**é—®é¢˜**: `_group_is_resident()` ä¸æ£€æŸ¥ `_gpu_group_inflight`,å¯¼è‡´åˆ¤å®šä¸å‡†ç¡®ã€‚

---

### é—®é¢˜ 4: CPU->GPU ä¼ è¾“æœªå®Œæˆå³æ ‡è®°ä¸º RESIDENT

#### ä»£ç ä½ç½®: [weight_streaming_manager.py:3168-3189](llama3/weight_streaming_manager.py#L3168-L3189)

```python
def prefetch_group_async(...):
    # ... H2D ä¼ è¾“ä»£ç  ...
    with torch.cuda.stream(h2d):
        for pname in param_names:
            p = self.name_to_param[pname]
            p.data = cpu_t.to(self.device, non_blocking=True)  # âš ï¸ å¼‚æ­¥

    # âŒ ç«‹å³è®°å½• event,ä¸ç­‰å¾…ä¼ è¾“å®Œæˆ
    self._record_group_ready_event(layer_idx, group)

    # âŒ ç«‹å³æ ‡è®°ä¸º RESIDENT
    with self._group_lock:
        self._gpu_group_ring.append(key)
        self._gpu_group_inflight.discard(key)
        self._set_state(key, "RESIDENT")  # âŒ è¿˜åœ¨ä¼ è¾“ä¸­!
```

**æ—¶åºæ¼æ´**:
```
T0: p.data = cpu_t.to(device, non_blocking=True)  # å¯åŠ¨å¼‚æ­¥ä¼ è¾“
T1: _record_group_ready_event()                   # è®°å½• event (å¼‚æ­¥)
T2: _set_state(key, "RESIDENT")                   # æ ‡è®°ä¸º RESIDENT
T3: [å¹¶å‘çº¿ç¨‹] _group_is_resident() æ£€æŸ¥           # âŒ è¿”å› False (æ•°æ®è¿˜åœ¨ä¼ è¾“)
T4: ... å‡ æ¯«ç§’åä¼ è¾“å®Œæˆ ...
T5: ç°åœ¨æ‰çœŸæ­£ RESIDENT
```

---

## ğŸ› ï¸ æ ¹æœ¬åŸå› æ€»ç»“

| é—®é¢˜ç±»åˆ« | å…·ä½“è¡¨ç° | å½±å“ |
|---------|---------|------|
| **Event è¯­ä¹‰è¯¯ç”¨** | `event.record()` åç«‹å³è®¤ä¸ºä¼ è¾“å®Œæˆ | å‡é˜³æ€§,missing tensors |
| **è¿‡æ—©é©±é€** | çª—å£åˆ¤å®šæ¿€è¿›,åˆšä¼ å®Œå°±è¢«è¸¢å‡º | é‡å¤åŠ è½½,æ€§èƒ½ä¸‹é™ |
| **çŠ¶æ€ä¸ä¸€è‡´** | å¤šä¸ªçŠ¶æ€æ ‡è®°ä¸åŒæ­¥ | é€»è¾‘æ··ä¹±,éš¾ä»¥è°ƒè¯• |
| **å¼‚æ­¥ä¼ è¾“æœªå®Œæˆå³æ ‡è®°** | `non_blocking=True` åç«‹å³æ”¹çŠ¶æ€ | å…¶ä»–çº¿ç¨‹çœ‹åˆ°é”™è¯¯çŠ¶æ€ |
| **ç«æ€æ¡ä»¶** | é¢„å–çº¿ç¨‹ vs é©±é€çº¿ç¨‹ vs è®¡ç®—çº¿ç¨‹ | éšæœº missing tensors |

---

## âœ… ä¿®å¤å»ºè®®

### 1. **ä¿®å¤ Event åŒæ­¥**

#### Before (é”™è¯¯):
```python
def _group_is_resident(self, layer_idx, group, wait_for_event=False):
    if wait_for_event:
        evt = self._group_events.get(key)
        if evt is not None:
            while not evt.query():  # âŒ è½®è¯¢ä¸å¯é 
                time.sleep(0.001)
```

#### After (æ­£ç¡®):
```python
def _group_is_resident(self, layer_idx, group, wait_for_event=False):
    if wait_for_event:
        evt = self._group_events.get(key)
        if evt is not None:
            evt.synchronize()  # âœ… ç¡®ä¿ä¼ è¾“å®Œæˆ
```

**æˆ–è€…æ›´ä¼˜é›…çš„åšæ³•**: åœ¨ compute stream ä¸Šç”¨ GPU ç«¯åŒæ­¥
```python
compute_stream.wait_event(evt)  # GPU ç«¯åŒæ­¥,ä¸é˜»å¡ CPU
```

---

### 2. **å»¶è¿ŸçŠ¶æ€æ ‡è®°**

#### Before (é”™è¯¯):
```python
def prefetch_group_async(...):
    with torch.cuda.stream(h2d):
        # ... H2D ä¼ è¾“ ...
        p.data = cpu_t.to(device, non_blocking=True)

    # âŒ ç«‹å³æ ‡è®°
    self._record_group_ready_event(layer_idx, group)
    self._set_state(key, "RESIDENT")
```

#### After (æ­£ç¡®):
```python
def prefetch_group_async(...):
    with torch.cuda.stream(h2d):
        # ... H2D ä¼ è¾“ ...
        p.data = cpu_t.to(device, non_blocking=True)

    # âœ… è®°å½• event,ä½†çŠ¶æ€ä¿æŒ INFLIGHT
    self._record_group_ready_event(layer_idx, group)
    # âš ï¸ ä¸ç«‹å³æ ‡è®°ä¸º RESIDENT

    # âœ… åœ¨å›è°ƒ/ä½¿ç”¨æ—¶æ‰åŒæ­¥å¹¶æ ‡è®°
    def _on_transfer_complete():
        evt = self._group_events[key]
        evt.synchronize()  # ç¡®ä¿å®Œæˆ
        self._set_state(key, "RESIDENT")
        self._gpu_group_inflight.discard(key)
        self._gpu_group_ring.append(key)
```

---

### 3. **ç»Ÿä¸€çŠ¶æ€æ£€æŸ¥**

#### åˆ›å»ºå•ä¸€çœŸå€¼æ¥æº:
```python
def _group_is_ready(self, layer_idx, group):
    """ç»Ÿä¸€çš„çŠ¶æ€æ£€æŸ¥: ç»¼åˆæ‰€æœ‰æ ‡è®°"""
    key = (layer_idx, group)

    # 1. æ£€æŸ¥æ˜¯å¦åœ¨ä¼ è¾“ä¸­
    if key in self._gpu_group_inflight:
        return False  # è¿˜åœ¨ä¼ è¾“,æœªå°±ç»ª

    # 2. æ£€æŸ¥ event æ˜¯å¦å®Œæˆ
    evt = self._group_events.get(key)
    if evt is not None and not evt.query():
        return False  # event æœªè§¦å‘,æœªå°±ç»ª

    # 3. æ£€æŸ¥å‚æ•°æ˜¯å¦çœŸçš„åœ¨ GPU
    suffixes = GROUPS[group]
    for suf in suffixes:
        p = self.name_to_param.get(f"layers.{layer_idx}.{suf}")
        if not (p and p.is_cuda and p.numel() > 0):
            return False  # å‚æ•°ä¸åœ¨ GPU

    return True  # æ‰€æœ‰æ£€æŸ¥é€šè¿‡
```

---

### 4. **ä¿å®ˆçš„é©±é€ç­–ç•¥**

#### å¢åŠ å®‰å…¨è¾¹ç•Œ:
```python
def _proactive_cleanup_old_groups(self, current_layer):
    # âœ… æ‰©å¤§ä¿æŠ¤çª—å£,é¿å…è¿‡æ—©é©±é€
    ahead = self.gpu_ahead_layers + 2   # +2 å®‰å…¨ä½™é‡
    behind = self.gpu_behind_layers + 1 # +1 å®‰å…¨ä½™é‡

    # âœ… é¢å¤–ä¿æŠ¤: è·³è¿‡æœ‰ pinned æ ‡è®°çš„ç»„
    if self._is_pinned(lyr, grp):
        continue

    # âœ… é¢å¤–ä¿æŠ¤: è·³è¿‡æœ‰æœªå®Œæˆ event çš„ç»„
    evt = self._group_events.get(key)
    if evt and not evt.query():
        continue  # è¿˜åœ¨ä¼ è¾“,ä¸é©±é€
```

---

### 5. **æ·»åŠ æ–­è¨€å’Œæ—¥å¿—**

```python
def _set_state(self, key, new_state):
    old_state = self._group_state.get(key, "CPU")

    # âœ… çŠ¶æ€è½¬æ¢åˆæ³•æ€§æ£€æŸ¥
    VALID_TRANSITIONS = {
        "CPU": ["INFLIGHT"],
        "INFLIGHT": ["RESIDENT", "CPU"],  # å…è®¸å¤±è´¥å›é€€
        "RESIDENT": ["EVICTING", "CPU"],
        "EVICTING": ["CPU"]
    }

    if new_state not in VALID_TRANSITIONS.get(old_state, []):
        raise RuntimeError(
            f"Invalid state transition for {key}: {old_state} -> {new_state}"
        )

    self._group_state[key] = new_state

    # âœ… è°ƒè¯•æ—¥å¿—
    if getattr(self, "debug_state", False):
        print(f"[WSM STATE] {key}: {old_state} -> {new_state}")
```

---

## ğŸ”¬ éªŒè¯æ–¹æ³•

### 1. **æ·»åŠ ä¸€è‡´æ€§æ£€æŸ¥**

```python
def _validate_consistency(self):
    """è°ƒè¯•ç”¨: éªŒè¯å„çŠ¶æ€æ ‡è®°ä¸€è‡´æ€§"""
    for key in self._gpu_group_ring:
        # æ£€æŸ¥1: ring ä¸­çš„å¿…é¡»æ˜¯ RESIDENT
        state = self._group_state.get(key, "CPU")
        assert state == "RESIDENT", f"{key} in ring but state={state}"

        # æ£€æŸ¥2: RESIDENT çš„å¿…é¡»æœ‰ event
        assert key in self._group_events, f"{key} RESIDENT but no event"

        # æ£€æŸ¥3: RESIDENT çš„å‚æ•°å¿…é¡»åœ¨ GPU
        assert self._group_is_resident(*key, wait_for_event=True), \
            f"{key} RESIDENT but params not on GPU"
```

### 2. **å‹åŠ›æµ‹è¯•**

```python
# åœ¨åˆå§‹åŒ–æ—¶å¯ç”¨ä¸¥æ ¼æ£€æŸ¥
os.environ["WSM_STRICT_MODE"] = "1"
os.environ["WSM_DEBUG_PREFETCH"] = "1"
os.environ["WSM_VERBOSE_MISMATCH"] = "1"

# æ¯æ¬¡çŠ¶æ€è½¬æ¢åéªŒè¯
if os.getenv("WSM_STRICT_MODE") == "1":
    self._validate_consistency()
```

---

## ğŸ“Š æ€§èƒ½å½±å“

| é—®é¢˜ | æ€§èƒ½æŸå¤± | åŸå›  |
|-----|---------|------|
| **é‡å¤åŠ è½½** | ~20-30% | åˆšé©±é€çš„ç»„ç«‹å³åˆè¢«è¯·æ±‚ |
| **å‡é˜³æ€§ missing** | ~10-15% | é‡å¤æ£€æŸ¥å’Œç­‰å¾… |
| **ç«æ€é”ç«äº‰** | ~5-10% | å¤šçº¿ç¨‹é¢‘ç¹æ£€æŸ¥çŠ¶æ€ |
| **æ€»è®¡** | **35-55%** | ç´¯ç§¯å¼€é”€ |

---

## ğŸ¯ ä¼˜å…ˆçº§ä¿®å¤é¡ºåº

1. **P0 (Critical)**: ä¿®å¤ Event åŒæ­¥ â†’ æ¶ˆé™¤ missing tensors
2. **P1 (High)**: å»¶è¿ŸçŠ¶æ€æ ‡è®° â†’ é¿å…å‡é˜³æ€§
3. **P2 (Medium)**: ç»Ÿä¸€çŠ¶æ€æ£€æŸ¥ â†’ ç®€åŒ–é€»è¾‘
4. **P3 (Low)**: ä¿å®ˆé©±é€ç­–ç•¥ â†’ æå‡ç¨³å®šæ€§
5. **P4 (Nice-to-have)**: æ·»åŠ éªŒè¯ â†’ é•¿æœŸç»´æŠ¤

---

## ğŸ“ ä»£ç å®¡æŸ¥æ¸…å•

- [ ] æ‰€æœ‰ `event.record()` åæ˜¯å¦æ­£ç¡®åŒæ­¥?
- [ ] æ‰€æœ‰çŠ¶æ€è½¬æ¢æ˜¯å¦åœ¨é”ä¿æŠ¤ä¸‹?
- [ ] `_group_is_resident()` æ˜¯å¦è€ƒè™‘ `_gpu_group_inflight`?
- [ ] é©±é€ç­–ç•¥æ˜¯å¦è¶³å¤Ÿä¿å®ˆ?
- [ ] æ˜¯å¦æœ‰å•ä¸€çœŸå€¼æ¥æºçš„çŠ¶æ€æ£€æŸ¥?
- [ ] æ˜¯å¦æ·»åŠ äº†çŠ¶æ€è½¬æ¢çš„åˆæ³•æ€§éªŒè¯?

---

## ç»“è®º

WSM çš„ "missing tensors" é—®é¢˜æ˜¯å…¸å‹çš„**å¼‚æ­¥ç³»ç»ŸçŠ¶æ€ç®¡ç†ä¸ä¸€è‡´**å¯¼è‡´çš„ã€‚æ ¸å¿ƒé—®é¢˜æ˜¯:

1. **è¯¯ä»¥ä¸º event è§¦å‘ = æ•°æ®ä¼ è¾“å®Œæˆ**
2. **çŠ¶æ€æ ‡è®°è¿‡æ—©,å®é™…æ•°æ®è¿˜åœ¨ä¼ è¾“**
3. **å¤šä¸ªçŠ¶æ€æ ‡è®°ä¸åŒæ­¥**
4. **é©±é€ç­–ç•¥è¿‡äºæ¿€è¿›**

ä¿®å¤éœ€è¦:
- æ­£ç¡®ç†è§£ CUDA event è¯­ä¹‰
- å»¶è¿ŸçŠ¶æ€æ ‡è®°åˆ°çœŸæ­£å®Œæˆæ—¶
- ç»Ÿä¸€çŠ¶æ€æ£€æŸ¥é€»è¾‘
- å¢åŠ å®‰å…¨è¾¹ç•Œ

é¢„æœŸæ”¶ç›Š: **æ€§èƒ½æå‡ 35-55%,æ¶ˆé™¤éšæœºé”™è¯¯**

---

ç”Ÿæˆæ—¶é—´: 2025-11-08
åˆ†æå·¥å…·: Claude Code (Sonnet 4.5)
