#!/usr/bin/env python3
"""
ç®€å•æµ‹è¯•è„šæœ¬ï¼šä½¿ç”¨ raw param store åŠ è½½ llama3.1-8b çš„ä¸€å±‚æƒé‡
"""

import sys
from pathlib import Path
sys.path.append(str(Path(__file__).parent))

import torch
from llama3.raw_param_store import ParamStore


def test_raw_param_store():
    """æµ‹è¯• raw param store èƒ½å¦æ­£å¸¸åŠ è½½ llama3.1-8b"""

    print("=" * 60)
    print("ğŸ§ª Testing Raw Param Store with LLaMA3.1-8B")
    print("=" * 60)

    manifest_path = "/data1/llama3.1-8B.runtime_manifest.json"

    try:
        # 1. åˆ›å»º ParamStore
        print("\n[1/4] åˆ›å»º ParamStore...")
        store = ParamStore(
            manifest_or_path=manifest_path,
            method="bytecopy",
            staging_mb=16,
            rw=False
        )
        print("âœ… ParamStore åˆ›å»ºæˆåŠŸ")

        # 2. è·å–å­˜å‚¨ç»Ÿè®¡ä¿¡æ¯
        print("\n[2/4] è·å–å­˜å‚¨ç»Ÿè®¡ä¿¡æ¯...")
        stats = store.get_storage_stats()
        print(f"   æ€»å‚æ•°æ•°: {stats['total_params']}")
        print(f"   æ€»å¤§å°: {stats['total_gb']:.2f} GB")
        print(f"   Stream å¤§å°: {stats['stream_gb']:.2f} GB")
        print(f"   Raw è®¾å¤‡: {stats['raw_device']}")
        print(f"   å—å¤§å°: {stats['block_size']}")

        # 3. åŠ è½½ç¬¬ 0 å±‚çš„æƒé‡ï¼ˆonly_stream=Trueï¼‰
        print("\n[3/4] åŠ è½½ç¬¬ 0 å±‚çš„ stream æƒé‡...")
        layer_0_tensors = store.fetch_layer(
            layer_id=0,
            only_stream=True
        )

        if layer_0_tensors:
            print(f"âœ… æˆåŠŸåŠ è½½ç¬¬ 0 å±‚ï¼Œå…± {len(layer_0_tensors)} ä¸ªå‚æ•°:")
            total_mb = 0
            for name, tensor in layer_0_tensors.items():
                mb = tensor.numel() * tensor.element_size() / (1024**2)
                total_mb += mb
                print(f"   - {name}: {list(tensor.shape)} {tensor.dtype} "
                      f"({mb:.2f} MB, pinned={tensor.is_pinned()})")
            print(f"   æ€»è®¡: {total_mb:.2f} MB")
        else:
            print("âš ï¸  ç¬¬ 0 å±‚æ²¡æœ‰ stream æƒé‡")

        # 4. æ ¡éªŒæ•°æ®å®Œæ•´æ€§ï¼ˆè¯»å–å‰ 64 å­—èŠ‚è¿›è¡Œæ ¡éªŒï¼‰
        print("\n[4/4] æ ¡éªŒæ•°æ®å®Œæ•´æ€§...")
        matched, total = store.sanity_check_layer(
            layer_id=0,
            tensors=layer_0_tensors,
            check_bytes=64,
            verbose=False
        )
        print(f"   æ ¡éªŒç»“æœ: {matched}/{total} åˆ†ç‰‡åŒ¹é…")
        if matched == total:
            print("   âœ… æ•°æ®å®Œæ•´æ€§æ ¡éªŒé€šè¿‡")
        else:
            print(f"   âš ï¸  æœ‰ {total - matched} ä¸ªåˆ†ç‰‡æ ¡éªŒå¤±è´¥")

        # 5. æµ‹è¯•å¼‚æ­¥åŠ è½½
        print("\n[5/5] æµ‹è¯•å¼‚æ­¥åŠ è½½ç¬¬ 1 å±‚...")
        future = store.fetch_layer_async(layer_id=1, only_stream=True)
        layer_1_tensors = future.result()

        if layer_1_tensors:
            total_mb = sum(t.numel() * t.element_size() for t in layer_1_tensors.values()) / (1024**2)
            print(f"âœ… å¼‚æ­¥åŠ è½½æˆåŠŸ: {len(layer_1_tensors)} ä¸ªå‚æ•°, {total_mb:.2f} MB")

        # 6. å…³é—­ store
        store.close()
        print("\nâœ… ParamStore å…³é—­æˆåŠŸ")

        print("\n" + "=" * 60)
        print("ğŸ‰ æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼Raw Param Store å·¥ä½œæ­£å¸¸")
        print("=" * 60)

        return True

    except Exception as e:
        print(f"\nâŒ æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False


if __name__ == "__main__":
    success = test_raw_param_store()
    sys.exit(0 if success else 1)
