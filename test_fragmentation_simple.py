#!/usr/bin/env python3
"""
ç®€å•çš„GPUå†…å­˜ç¢ç‰‡åŒ–æ£€æµ‹è„šæœ¬
å¿«é€Ÿæ£€æµ‹æƒé‡æµå¼ä¼ è¾“è¿‡ç¨‹ä¸­çš„å†…å­˜ç¢ç‰‡åŒ–æƒ…å†µ
"""

import torch
import gc
import time
import json

def quick_fragmentation_test():
    """å¿«é€Ÿç¢ç‰‡åŒ–æµ‹è¯•"""
    print("ğŸ” GPUå†…å­˜ç¢ç‰‡åŒ–å¿«é€Ÿæ£€æµ‹")
    print("=" * 40)
    
    if not torch.cuda.is_available():
        print("âŒ CUDAä¸å¯ç”¨")
        return
    
    # æ¸…ç†åˆå§‹çŠ¶æ€
    torch.cuda.empty_cache()
    torch.cuda.reset_peak_memory_stats()
    
    def get_fragmentation_info():
        allocated = torch.cuda.memory_allocated()
        reserved = torch.cuda.memory_reserved()
        stats = torch.cuda.memory_stats()
        
        return {
            'allocated_mb': allocated / 1024**2,
            'reserved_mb': reserved / 1024**2,
            'fragmentation_ratio': (reserved - allocated) / reserved if reserved > 0 else 0,
            'segments': stats.get('segment.all.current', 0),
        }
    
    print("ğŸ“Š åŸºç¡€å†…å­˜ä¿¡æ¯:")
    initial = get_fragmentation_info()
    print(f"   åˆå§‹åˆ†é…: {initial['allocated_mb']:.1f} MB")
    print(f"   åˆå§‹ä¿ç•™: {initial['reserved_mb']:.1f} MB")
    print(f"   åˆå§‹ç¢ç‰‡åŒ–: {initial['fragmentation_ratio']:.3f}")
    
    # æ¨¡æ‹Ÿæƒé‡åˆ†é…å’Œé‡Šæ”¾æ¨¡å¼
    tensors = []
    fragmentation_history = []
    
    # æ¨¡æ‹Ÿä¸åŒå¤§å°çš„æƒé‡çŸ©é˜µ
    weight_sizes = [
        (2048, 2048),    # ~16MB
        (4096, 1024),    # ~16MB  
        (1024, 4096),    # ~16MB
        (8192, 512),     # ~16MB
        (512, 8192),     # ~16MB
        (1024, 1024),    # ~4MB
    ]
    
    print("\nğŸ”„ æ¨¡æ‹Ÿæƒé‡åŠ è½½æ¨¡å¼:")
    max_cached = 4  # æ¨¡æ‹Ÿmax_cached_layers=4
    
    for step in range(10):
        print(f"   Step {step+1}: ", end="")
        
        try:
            # æ¨¡æ‹Ÿæƒé‡åŠ è½½
            if len(tensors) >= max_cached:
                # LRUé€å‡º
                del tensors[0]
                tensors = tensors[1:]
                gc.collect()
                print("é€å‡º+", end="")
            
            # åŠ è½½æ–°æƒé‡ï¼ˆé€‰æ‹©ä¸åŒå¤§å°ï¼‰
            size = weight_sizes[step % len(weight_sizes)]
            weight = torch.randn(size, device='cuda')
            tensors.append(weight)
            
            info = get_fragmentation_info()
            fragmentation_history.append(info)
            
            print(f"åŠ è½½{size} -> ç¢ç‰‡åŒ–: {info['fragmentation_ratio']:.3f} "
                  f"(æ®µæ•°: {info['segments']})")
            
            # æ£€æŸ¥é«˜ç¢ç‰‡åŒ–
            if info['fragmentation_ratio'] > 0.3:
                print(f"      âš ï¸  é«˜ç¢ç‰‡åŒ–æ£€æµ‹åˆ°!")
                
        except torch.cuda.OutOfMemoryError:
            print("âŒ OOM")
            break
    
    # åˆ†æç»“æœ
    if fragmentation_history:
        max_frag = max(h['fragmentation_ratio'] for h in fragmentation_history)
        avg_frag = sum(h['fragmentation_ratio'] for h in fragmentation_history) / len(fragmentation_history)
        max_segments = max(h['segments'] for h in fragmentation_history)
        
        print(f"\nğŸ“ˆ ç¢ç‰‡åŒ–åˆ†æç»“æœ:")
        print(f"   æœ€å¤§ç¢ç‰‡åŒ–æ¯”ä¾‹: {max_frag:.3f}")
        print(f"   å¹³å‡ç¢ç‰‡åŒ–æ¯”ä¾‹: {avg_frag:.3f}")
        print(f"   æœ€å¤§å†…å­˜æ®µæ•°: {max_segments}")
        
        # ä¸¥é‡ç¨‹åº¦è¯„ä¼°
        if max_frag > 0.4:
            severity = "ğŸ”´ ä¸¥é‡"
            recommendations = [
                "ç«‹å³å¢åŠ max_cached_layersåˆ°6-8",
                "ä½¿ç”¨å†…å­˜æ± é¢„åˆ†é…",
                "è€ƒè™‘æƒé‡é‡åŒ–å‡å°‘å†…å­˜ä½¿ç”¨"
            ]
        elif max_frag > 0.3:
            severity = "ğŸŸ¡ ä¸­ç­‰"
            recommendations = [
                "å¢åŠ max_cached_layersåˆ°5-6",
                "å®šæœŸè°ƒç”¨torch.cuda.empty_cache()"
            ]
        elif max_frag > 0.15:
            severity = "ğŸŸ¢ è½»å¾®"
            recommendations = [
                "å½“å‰é…ç½®å¯æ¥å—",
                "å¯ä»¥è€ƒè™‘å°å¹…ä¼˜åŒ–"
            ]
        else:
            severity = "âœ… è‰¯å¥½"
            recommendations = [
                "å†…å­˜ä½¿ç”¨æ•ˆç‡å¾ˆé«˜",
                "æ— éœ€è°ƒæ•´"
            ]
        
        print(f"   ä¸¥é‡ç¨‹åº¦: {severity}")
        print(f"   å»ºè®®:")
        for rec in recommendations:
            print(f"     - {rec}")
    
    # æ¸…ç†
    del tensors
    gc.collect()
    torch.cuda.empty_cache()

def monitor_model_fragmentation():
    """ç›‘æ§æ¨¡å‹æ¨ç†è¿‡ç¨‹ä¸­çš„ç¢ç‰‡åŒ–ï¼ˆå¦‚æœæœ‰æ¨¡å‹çš„è¯ï¼‰"""
    print(f"\nğŸ¤– ç›‘æ§æ¨¡å‹ç¢ç‰‡åŒ–ï¼ˆå¦‚æœå¯ç”¨æƒé‡æµå¼ä¼ è¾“ï¼‰")
    
    try:
        # æ£€æŸ¥æ˜¯å¦å¯ä»¥å¯¼å…¥
        from llama3.generator import LLaMA
        from llama3.weight_streaming_manager import WeightStreamingManager
        
        print("âœ… å¯ä»¥åˆ›å»ºå¸¦ç¢ç‰‡åŒ–ç›‘æ§çš„WeightStreamingManager:")
        print("   åœ¨generatorä¸­æ·»åŠ monitor_fragmentation=Trueå‚æ•°")
        print("   ä¾‹å¦‚:")
        print("   streaming_config = {")
        print("       'monitor_fragmentation': True,")
        print("       'max_cached_layers': 4,")
        print("       'prefetch_distance': 2")
        print("   }")
        
    except ImportError as e:
        print(f"âŒ æ— æ³•å¯¼å…¥æ¨¡å‹ç»„ä»¶: {e}")
        print("   å¯ä»¥ä½¿ç”¨test_memory_fragmentation.pyè¿›è¡Œè¯¦ç»†æµ‹è¯•")

def main():
    """ä¸»å‡½æ•°"""
    quick_fragmentation_test()
    monitor_model_fragmentation()
    
    print(f"\nğŸ’¡ å…¶ä»–æ£€æµ‹æ–¹æ³•:")
    print(f"1. ä½¿ç”¨nvidia-smiç›‘æ§GPUå†…å­˜ä½¿ç”¨")
    print(f"2. è¿è¡Œtest_memory_fragmentation.pyè¿›è¡Œè¯¦ç»†åˆ†æ")
    print(f"3. åœ¨æƒé‡æµå¼ä¼ è¾“ä¸­å¯ç”¨monitor_fragmentation=True")
    print(f"4. ä½¿ç”¨torch.profiler.profile()è¿›è¡Œå†…å­˜åˆ†æ")

if __name__ == "__main__":
    main()